{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chlorophyll\n",
    "\n",
    "<BR>\n",
    "<img src=\"./images/misc/revelle.jpg\" style=\"float: left;\" alt=\"drawing\" width=\"900\"/>\n",
    "<div style=\"clear: left\"><BR>\n",
    "\n",
    "\n",
    "This is the research vessel R/V Revelle at work in the southern ocean near a tabular iceberg. \n",
    "The vessel is just under 100 meters in length. \n",
    "Ninety percent of the iceberg is under the surface of the water. \n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "    \n",
    "This Jupyter notebook explores the upper 200 meters of the ocean near the coast of Oregon.\n",
    "We are particularly interested in the phytoplankton that use chlorophyll to store energy from the sun.\n",
    "For more on this please visit the [Interactive Oceans](https://interactiveoceans.washington.edu) portal.\n",
    "\n",
    "### Guide to this and related notebooks; including intended audience\n",
    "\n",
    "    \n",
    "* The narrative here is fairly technical and streamlined. It is intended for college or (enthusiastic) secondary school students.\n",
    "* For a narrative intended for middle school see the `chlorophyll_ms.ipynb` notebook. \n",
    "* Background material has been placed in `chlorophyll_background.ipnb`\n",
    "* A focus on data -- how to get it and tidy it up -- is in the `rca_fetch.ipynb` notebook.\n",
    "* Technical details, for example concerning time and plotting, are in the `mechanics.ipynb` notebook. \n",
    "\n",
    "\n",
    "### Locations\n",
    "    \n",
    "    \n",
    "Here are the three data measurement sites within the Regional Cabled Array (RCA)\n",
    "   \n",
    "    \n",
    "Shallow profilers\n",
    "\n",
    "```\n",
    "Site name               Lat               Lon\n",
    "------------------      ---               ---\n",
    "Oregon Offshore         44.37415          -124.95648\n",
    "Oregon Slope Base       44.52897          -125.38966 \n",
    "Axial Base              45.83049          -129.75326\n",
    "```   \n",
    "\n",
    "# This image should be local\n",
    "\n",
    "<BR>\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/media.ooica.net/wp-content/uploads/2019/01/11005601/screenshot2018-12-07at1.55.21pm.png\"\n",
    " align=\"float: left\"\n",
    " width=\"30%\"\n",
    " alt=\"Regional Cabled Array image\">\n",
    "<BR>\n",
    "\n",
    "A camera is deployed into the Regional Cabled Array (RCA) by a Remotely Operated Vehicle (ROV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini-source control: Last copied 29-SEP-2020: to tilt*, chlorophyll*, rca*, argo*\n",
    "#                      last revised 09-OCT-2020\n",
    "import os, sys, time, glob\n",
    "\n",
    "from IPython.display import clear_output             # use inside loop with clear_output(wait = True) followed by print(i)\n",
    "import warnings                                      # use with warnings.filterwarnings('ignore') or 'once'\n",
    "\n",
    "home_dir = os.getenv(\"HOME\")\n",
    "this_dir = home_dir + '/chlorophyll/'\n",
    "data_dir = '/data/'\n",
    "data1_dir = '/data1'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mplcolors\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "from numpy import datetime64 as dt64, timedelta64 as td64\n",
    "\n",
    "def doy(theDatetime): return 1 + int((theDatetime - dt64(str(theDatetime)[0:4] + '-01-01')) / td64(1, 'D')) # 1, 2, .... , 365, [366]\n",
    "def dt64_from_doy(year, doy): return dt64(str(year) + '-01-01') + td64(doy-1, 'D')\n",
    "def day_of_month_to_string(d): return str(d) if d > 9 else '0' + str(d)\n",
    "\n",
    "print('\\nJupyter Notebook running Python {}'.format(sys.version_info[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load streamlined datasets\n",
    "\n",
    "Source datasets have been simplified and combined for a number of sensors. A variable starting with `ds_` is an XArray DataSet. \n",
    "\n",
    "* optaa is turbidity (from both optical attenuation and absorption)\n",
    "* phsen is pH (acid/base)\n",
    "* ctdpf is salinity, temperature and depth\n",
    "* parad is sunlight available for photosynthesis\n",
    "* spkir is also sunlight\n",
    "* flort is chlorophyll concentration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrophotometer ([`optaa`](https://oceanobservatories.org/instrument-class/optaa/)) at **Oregon Slope Base**, 2019\n",
    "\n",
    "\n",
    "<BR>\n",
    "<img src=\"./images/spectrophotometer/osb_2019_sp_availability.png\" style=\"float: left;\" alt=\"drawing\" width=\"1200\"/>\n",
    "<div style=\"clear: left\"><BR>\n",
    "    \n",
    "    \n",
    "...data availability per Interactive Oceans data portal. 2019 is somewhat intermittent, stops in September. \n",
    "\n",
    "\n",
    "Action: Move `mechanics.ipynb` notes to a better location.\n",
    "    \n",
    "    \n",
    "Some notes from the expository work on this data:\n",
    "\n",
    "\n",
    "* The sensor located on the Oregon Slope Base shallow profiler is not simply \"on all the time\"\n",
    "    * It runs episodically, twice per day: During the midnight and noon ascents (but *not* during descent)\n",
    "    * RCA shallow profilers execute nine profiles per day\n",
    "    * The two of these mentioned (midnight, noon) feature nitrate measurements on *descent*\n",
    "    * These two special profiles take upwards of two hours to complete. The others are faster.\n",
    "    * In between profiles the profiler rests in its platform at a depth of 200 meters\n",
    "    * The ascent minimum depth is five meters; this varies with conditions\n",
    "* Spectrophotometer\n",
    "    * Data are optical absorption (abbreviated OA), beam attenuation (abbreviated BA), time and depth\n",
    "    * Base sample rate is about 3.7 samples per second\n",
    "    * 86 spectral channels; wavelength ~(400nm + channel number x 4nm)\n",
    "    * Channels 0, 83, 84 and 85 are `nan` values (not usable) for both OA and BA\n",
    "    * Channel width is ~20nm so the channels overlap\n",
    "    * Both OA and BA data are idiosyncratic\n",
    "        * The midnight OA data are quantized in a peculiar manner; see charts below\n",
    "        * The noon OA are *somewhat* quantized but have more data-like structure\n",
    "        * Both midnight and noon BA data give a more typical clear signal; but substantial noise and variance are both apparent\n",
    "* Un-answered questions\n",
    "    * Why are OA data so different in midnight versus noon? \n",
    "    * Is OA and BA combined in to some sort of turbidity measure?\n",
    "    * What wavelength ranges (e.g. green) are of particular interest?\n",
    "    * Can check against fluorometer or other data? SME evaluation suggests this but is sadly rather brief; see link below.\n",
    "* References froom OOI\n",
    "    * [Table of instruments / designators / locations](https://oceanobservatories.org/instrument-series/optaad/)\n",
    "    * [Spectrophotometer page](https://oceanobservatories.org/instrument-class/optaa/)\n",
    "    * [Subject Matter Expert evaluation](https://oceanobservatories.org/2016/07/successful-sme-evaluation-spectrophotometer-optaa/)\n",
    "    * [Code](https://github.com/oceanobservatories/ion-functions/blob/master/ion_functions/data/opt_functions.py)\n",
    "\n",
    "\n",
    "Paraphrasing the Subject Matter Export evaluation (link above): \n",
    "\n",
    "\n",
    "> Dr. Boss (SME) verified 1.5 months of data (April-May 2015): Processing and plotting data using the raw data and vendor calibration files \n",
    "> from the AC-S, salinity and temperature from a collocated CTD data to correct absorption and attenuation median spectra and scattering, \n",
    "> and data from a collocated fluorometer to cross-check the chlorophyll and POC results.\n",
    "> \n",
    "> Consistency between the sensors suggests that they did not foul during the deployment. Not only did his results show that accurate data \n",
    "> was being produced by all the sensors in question, but the AC-S (an extremely sensitive instrument normally deployed for very short periods\n",
    "> of time) did not drift noticeably during the deployment period, a notable achievement.\n",
    "\n",
    "\n",
    "\n",
    "From the [spec sheet on Optical Absorption](https://oceanobservatories.org/wp-content/uploads/2015/10/1341-00700_Data_Product_SPEC_OPTABSN_OOI.pdf):\n",
    "\n",
    "\n",
    "> The primary instrument (OPTAA) is the WET Labs ac-s spectral absorption and attenuation meter. \n",
    "The instrument provides a 75 wavelength output from approximately 400–750 nm with approximately \n",
    "4 nm steps. Individual filter steps have a full-width half maximum response that\n",
    "range between about 10 to 18 nm. \n",
    ">\n",
    "> There are a total of 35 OPTAA instruments deployed\n",
    "throughout the initial OOI construction and integrated into the Pioneer, Endurance, Regional and\n",
    "Global arrays. They are deployed at fixed depths (near-surface, mid-water column and sea floor)\n",
    "and installed on moored profilers.\n",
    ">\n",
    "> The ac-s performs concurrent measurements of the water attenuation and absorption \n",
    "(the latter called 'OPTABSN').\n",
    ">\n",
    "> OPTABSN is a L2 product in that computation requires the raw signals emanating from a properly\n",
    "calibrated and configured instrument as well as water temperature (TEMPWAT) and practical\n",
    "salinity (PRACSAL) derived from a co-located and synchronized CTD. \n",
    ">\n",
    "> While small corrections\n",
    "for salinity are available at visible wavelengths (< 700 nm), temperature and salinity corrections\n",
    "are more significant at infrared wavelengths (> 700 nm) and must be performed on both the\n",
    "absorption and attenuation (OPBATTN) signals.\n",
    "\n",
    "\n",
    "The \n",
    "[beam attenuation spec sheet](https://oceanobservatories.org/wp-content/uploads/2015/10/1341-00690_Data_Product_SPEC_OPTATTN_OOI.pdf)\n",
    "is similar. Both give a mathematical basis for the data as well as (MATLAB?) code. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### left off here\n",
    "\n",
    "\n",
    "* **1 Hour 2 Minutes 49 Seconds: Duration of the first profile. 3.7 samples per second.**\n",
    "* **The x-axis for oa must be locked down**\n",
    "* **Month-day picker shows changing structure and P/A variation** \n",
    "* P/A by date still needed...\n",
    "    * [OOI interface version of P/A](https://ooinet.oceanobservatories.org/data_access/?search=OPTAA#RS01SBPS-SF01A-3B-OPTAAD101)\n",
    "* **The first profile is 7:22 Zulu so we'll call that midnight**\n",
    "* **Validated: Ascent**\n",
    "* From here go to nitrate; on the descent? \n",
    "    * Is there obvious correlation?\n",
    "* **Spec sheets only give per-channel formulas for OA and BA.** \n",
    "* Is there a turbidity derivable from OA + BA?\n",
    "* **The oa semi-quantization looks like NON-SIGNAL to the right of actual signal in the charts**\n",
    "* **OOI has not found the time / resources to make this data usable**\n",
    "* **Wavelengths are 400 - 750 nm in 4nm intervals. (IR > 700nm) Of 87 implied channels we see 82 working.**\n",
    "* **86 channels: 3 or 4 are nan for OA and BA. WetLabs idiosyncrasy maybe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#\n",
    "# Spectrophotometer\n",
    "#   OA = Optical Absorbance (deferred owing to pathologies in the data, particularly midnight)\n",
    "#   BA = Beam Absorbance\n",
    "#\n",
    "####################\n",
    "\n",
    "# single consolidated data read\n",
    "ds_optaa = xr.open_dataset(data_dir + 'rca/simpler/osb_sp_optaa_2019.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stable frozen code: skip down for current revision work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "m_strs = ['01', '02', '03', '04', '05', '06', '07', '08', '09']           # months\n",
    "m_days = [31, 28, 31, 30, 31, 30, 31, 31, 30]                             # days per month in 2019\n",
    "\n",
    "month_index = 0                                                           # manage time via months and days; 0 is January\n",
    "month_str   = m_strs[month_index]  \n",
    "year_str    = '2019'\n",
    "\n",
    "channel_indices = [2, 12, 22, 32, 42, 52, 62, 72, 82]                     # 86 channels with meh on the first two and final three\n",
    "n_indices = len(channel_indices)                                          #   ...hence we use reliable channels 2, 12, ..., 82\n",
    "\n",
    "depth_start, depth_end, depth_delta = 5., 210., 0.25                      # bin depth to reduce noise a bit                      \n",
    "depth_start, depth_end, depth_delta = 20., 200., 10.                      # bin depth to reduce noise a bit                      \n",
    "\n",
    "# for day_index in range(m_days[month_index]):                                   # loop: days of a chosen month \n",
    "for day_index in range(1):\n",
    "    \n",
    "    day_str = day_of_month_to_string(day_index+1)\n",
    "    clear_output(wait = True)                                                      # monitor progress\n",
    "    print(\"on day\", day_str)\n",
    "    \n",
    "    # see mechanics.ipynb for time slicing\n",
    "    ascent1_start_string = year_str + '-' + month_str + '-' + day_str + 'T07:00:00'       # Zulu times bounding both ascents as strings\n",
    "    ascent1_close_string = year_str + '-' + month_str + '-' + day_str + 'T10:00:00'\n",
    "    ascent2_start_string = year_str + '-' + month_str + '-' + day_str + 'T20:00:00'\n",
    "    ascent2_close_string = year_str + '-' + month_str + '-' + day_str + 'T23:00:00'\n",
    "\n",
    "    ds_midn = ds_optaa.sel(time=slice(dt64(ascent1_start_string), dt64(ascent1_close_string))).drop_vars('optical_absorption').swap_dims({'time':'int_ctd_pressure'})\n",
    "    ds_noon = ds_optaa.sel(time=slice(dt64(ascent2_start_string), dt64(ascent2_close_string))).drop_vars('optical_absorption').swap_dims({'time':'int_ctd_pressure'}) \n",
    "    \n",
    "    ########################################\n",
    "    # fix:\n",
    "    #   This section is the heavy lift before the charting section: averaging into depth bins.\n",
    "    #   The code needs improvement.\n",
    "    #       It resorts to compiling results into three lists for this day (should be an XArray Dataset).\n",
    "    #       It uses a for-loop over depths.\n",
    "    #       It is slow.\n",
    "    \n",
    "    ba_pressure, ba_midn, ba_noon = [], [], []\n",
    "\n",
    "    # looping through pressures using where() to focus on a particular range, average BA\n",
    "    for p in np.arange(depth_start, depth_end, depth_delta):\n",
    "        \n",
    "        midn0 = ds_midn.where(ds_midn.int_ctd_pressure > p, drop=True)                                  \n",
    "        midn1 = midn0.where(midn0.int_ctd_pressure <= p + depth_delta, drop=True).beam_attenuation.mean(axis=0, skipna=True)                                                                                                        \n",
    "\n",
    "        noon0 = ds_noon.where(ds_noon.int_ctd_pressure > p, drop=True)                                  \n",
    "        noon1 = noon0.where(noon0.int_ctd_pressure <= p + depth_delta, drop=True).beam_attenuation.mean(axis=0, skipna=True)                                                                                                         \n",
    "\n",
    "        ba_midn.append([float(midn1[i]) for i in range(86)])   \n",
    "        ba_noon.append([float(noon1[i]) for i in range(86)])\n",
    "        ba_pressure.append(p + depth_delta/2.)\n",
    "\n",
    "    midn_xpose = list(map(list, zip(*ba_midn)))      # this is the reduced 86 x depth-cells list...\n",
    "    noon_xpose = list(map(list, zip(*ba_noon)))\n",
    "\n",
    "    ################################\n",
    "    ## charting: left = midnight, right = noon; saving as png\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(36,18), tight_layout=True)\n",
    "    for chan_sel_index in range(n_indices):                              # will run 0, 1, ..., 8: indices 2, 12, ..., 82\n",
    "        axs[0].plot(midn_xpose[channel_indices[chan_sel_index]], ba_pressure,  marker='^', color='r'); \n",
    "        axs[1].plot(noon_xpose[channel_indices[chan_sel_index]], ba_pressure,  marker='o', color='g'); \n",
    "        axs[0].set(xlim = (.0, .6), ylim = (200., 0.), title='BA midnight')\n",
    "        axs[1].set(xlim = (.0, .6), ylim = (200., 0.), title='BA noon')\n",
    "\n",
    "    # sanity check: Superimpose un-resampled data as a scatter on the second displayed spectrum (index 12)\n",
    "    axs[0].scatter(ds_midn.beam_attenuation.isel(wavelength=channel_indices[1]), ds_midn.int_ctd_pressure, marker=',', s=1., color='b'); \n",
    "    axs[1].scatter(ds_noon.beam_attenuation.isel(wavelength=channel_indices[1]), ds_noon.int_ctd_pressure, marker=',', s=1., color='k'); \n",
    "\n",
    "#     figure_filename = '/data1/optaa/BA_midn_noon_2019_' + month_str + '_' + day_str + '.png'\n",
    "#     fig.savefig(figure_filename)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "m_strs = ['01', '02', '03', '04', '05', '06', '07', '08', '09']           # months\n",
    "m_days = [31, 28, 31, 30, 31, 30, 31, 31, 30]                             # days per month in 2019\n",
    "\n",
    "month_index = 0                                                           # manage time via months and days; 0 is January\n",
    "month_str   = m_strs[month_index]  \n",
    "year_str    = '2019'\n",
    "\n",
    "channel_indices = [2, 12, 22, 32, 42, 52, 62, 72, 82]                     # 86 channels with meh on the first two and final three\n",
    "n_indices = len(channel_indices)                                          #   ...hence we use reliable channels 2, 12, ..., 82\n",
    "\n",
    "depth_start, depth_end, depth_delta = 5., 210., 0.25                      # bin depth to reduce noise a bit                      \n",
    "depth_start, depth_end, depth_delta = 20., 200., 10.                      # bin depth to reduce noise a bit                      \n",
    "depth_start, depth_end, depth_delta = 20., 25., 10.                      # bin depth to reduce noise a bit                      \n",
    "\n",
    "# for day_index in range(m_days[month_index]):                                   # loop: days of a chosen month \n",
    "for day_index in range(1):\n",
    "    \n",
    "    day_str = day_of_month_to_string(day_index+1)\n",
    "    clear_output(wait = True)                                                      # monitor progress\n",
    "    print(\"on day\", day_str)\n",
    "    \n",
    "    # see mechanics.ipynb for time slicing\n",
    "    ascent1_start_string = year_str + '-' + month_str + '-' + day_str + 'T07:00:00'       # Zulu times bounding both ascents as strings\n",
    "    ascent1_close_string = year_str + '-' + month_str + '-' + day_str + 'T10:00:00'\n",
    "    ascent2_start_string = year_str + '-' + month_str + '-' + day_str + 'T20:00:00'\n",
    "    ascent2_close_string = year_str + '-' + month_str + '-' + day_str + 'T23:00:00'\n",
    "\n",
    "    # pull out the BA and prioritize dimension 'depth' but no binning is done just yet: For both midnight and noon ascents\n",
    "    ds_midn = ds_optaa.sel(time=slice(dt64(ascent1_start_string), dt64(ascent1_close_string))).drop_vars('optical_absorption').swap_dims({'time':'int_ctd_pressure'})\n",
    "    ds_noon = ds_optaa.sel(time=slice(dt64(ascent2_start_string), dt64(ascent2_close_string))).drop_vars('optical_absorption').swap_dims({'time':'int_ctd_pressure'}) \n",
    "    \n",
    "    ba_midn, ba_noon = [], []    # iterable lists of data arrays including time dimension 'doy'\n",
    "    ba_pressure = []\n",
    "    \n",
    "    # looping through pressures using where() to focus on a particular range, average BA\n",
    "    for p in np.arange(depth_start, depth_end, depth_delta):\n",
    "        \n",
    "        midn0 = ds_midn.where(ds_midn.int_ctd_pressure > p, drop=True)       # result: Dataset\n",
    "        midn1 = midn0.where(midn0.int_ctd_pressure <= p + depth_delta, drop=True).beam_attenuation.mean(axis=0, skipna=True)                                                                                                        \n",
    "\n",
    "        noon0 = ds_noon.where(ds_noon.int_ctd_pressure > p, drop=True)                                  \n",
    "        noon1 = noon0.where(noon0.int_ctd_pressure <= p + depth_delta, drop=True).beam_attenuation.mean(axis=0, skipna=True)                                                                                                         \n",
    "\n",
    "        print(type(midn1), type(noon1), noon1.dims, noon1.coords)\n",
    "        \n",
    "        ba_midn.append(midn1)   \n",
    "        ba_noon.append(noon1)\n",
    "        ba_pressure.append(p + depth_delta/2.)\n",
    "\n",
    "    midn_xpose = list(map(list, zip(*ba_midn)))      # this is the reduced 86 x depth-cells list...\n",
    "    noon_xpose = list(map(list, zip(*ba_noon)))\n",
    "\n",
    "    ################################\n",
    "    ## charting: left = midnight, right = noon; saving as png\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(36,18), tight_layout=True)\n",
    "    for chan_sel_index in range(n_indices):                              # will run 0, 1, ..., 8: indices 2, 12, ..., 82\n",
    "        axs[0].plot(midn_xpose[channel_indices[chan_sel_index]], ba_pressure,  marker='^', color='r'); \n",
    "        axs[1].plot(noon_xpose[channel_indices[chan_sel_index]], ba_pressure,  marker='o', color='g'); \n",
    "        axs[0].set(xlim = (.0, .6), ylim = (200., 0.), title='BA midnight')\n",
    "        axs[1].set(xlim = (.0, .6), ylim = (200., 0.), title='BA noon')\n",
    "\n",
    "    # sanity check: Superimpose un-resampled data as a scatter on the second displayed spectrum (index 12)\n",
    "    axs[0].scatter(ds_midn.beam_attenuation.isel(wavelength=channel_indices[1]), ds_midn.int_ctd_pressure, marker=',', s=1., color='b'); \n",
    "    axs[1].scatter(ds_noon.beam_attenuation.isel(wavelength=channel_indices[1]), ds_noon.int_ctd_pressure, marker=',', s=1., color='k'); \n",
    "\n",
    "#     figure_filename = '/data1/optaa/BA_midn_noon_2019_' + month_str + '_' + day_str + '.png'\n",
    "#     fig.savefig(figure_filename)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_midn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daba=ds_midn.beam_attenuation\n",
    "daba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dalist = []\n",
    "for thisday in range(4):\n",
    "    datmp = xr.DataArray(np.random.randn(1,4,7), dims=(\"day\", \"wavel\", \"deep\"), coords={\"day\":[thisday], \"deep\": [i for i in range(0, 70, 10)], \"wavel\":[i for i in range(4)]})\n",
    "    datmp.attrs['long_name']='some random stuff' + str(i); \n",
    "    datmp.attrs['units']='barn yard atmospheres'\n",
    "    # datmp, datmp.attrs, datmp.values, datmp.dims, datmp.coords\n",
    "    dalist.append(datmp)\n",
    "\n",
    "dalist[3].coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstmp = xr.concat(dalist, dim=\"day\")\n",
    "dstmp.dims, dalist[0].dims, dstmp.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.DataArray(np.random.randn(2, 3), dims=(\"x\", \"y\"), coords={\"x\": [10, 20]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional `optaa` continues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#\n",
    "# This cell sequence runs through optical absorption and beam attenuation for midnight and noon profile ascents in 2019\n",
    "#\n",
    "####################\n",
    "\n",
    "m_strs = ['01', '02', '03', '04', '05', '06', '07', '08', '09']           # months\n",
    "m_days = [31, 28, 31, 30, 31, 30, 31, 31, 30]                             # days per month in 2019\n",
    "\n",
    "def day_of_month_to_string(d): return str(d) if d > 9 else '0' + str(d)\n",
    "\n",
    "month_index = 0                                                           # selects January\n",
    "month_str = m_strs[0]                                                     \n",
    "\n",
    "plot_base_dimension = 2.1\n",
    "\n",
    "# for i in range(m_days[month_index]):                                    # loop over days of the month \n",
    "for i in range(1, 2):                                                        # temporary substitute: one day \n",
    "    \n",
    "    # The code in this loop is focused on a single day of a particular month; both ascents (midnight and noon)\n",
    "    \n",
    "    day_str = day_of_month_to_string(i+1)\n",
    "\n",
    "    # see mechanics.ipynb for time slicing\n",
    "    ascent1_start_string = '2019-' + month_str + '-' + day_str + 'T07:00:00'       # Zulu times bounding both ascents as strings\n",
    "    ascent1_close_string = '2019-' + month_str + '-' + day_str + 'T10:00:00'\n",
    "    ascent2_start_string = '2019-' + month_str + '-' + day_str + 'T20:00:00'\n",
    "    ascent2_close_string = '2019-' + month_str + '-' + day_str + 'T23:00:00'\n",
    "\n",
    "    ds_ascent1 = ds_optaa.sel(time=slice(dt64(ascent1_start_string), dt64(ascent1_close_string)))     # pulls 14k samples for one hour-long ascent: 3600 x SPS, both OA and BA\n",
    "    ds_ascent2 = ds_optaa.sel(time=slice(dt64(ascent2_start_string), dt64(ascent2_close_string)))     #   This retains all 86 spectral channels for both OA and BA\n",
    "\n",
    "    # As channels 0, 83, 84, and 85 tend to be nan we choose \"likely ok\" channels 2 - 82 step 10; so nine representatives across the spectrum\n",
    "    channel_indices = [2, 12, 22, 32, 42, 52, 62, 72, 82]\n",
    "    n_indices = len(channel_indices)\n",
    "    da_oa1, da_ba1, da_oa2, da_ba2 = [], [], [], []                        # These will be DataArrays for OA and BA for midnight and noon ascents\n",
    "\n",
    "    for idx in channel_indices:\n",
    "        da_oa1.append(ds_ascent1.optical_absorption.isel(wavelength=idx))          # Selecting out the nine spectral channels\n",
    "        da_ba1.append(ds_ascent1.beam_attenuation.isel(wavelength=idx))\n",
    "        da_oa2.append(ds_ascent2.optical_absorption.isel(wavelength=idx))\n",
    "        da_ba2.append(ds_ascent2.beam_attenuation.isel(wavelength=idx))\n",
    "\n",
    "    da_depth1 = ds_ascent1.int_ctd_pressure                                        # corresponding pressures for midnight and noon ascents\n",
    "    da_depth2 = ds_ascent2.int_ctd_pressure\n",
    "\n",
    "    # subplots: 9 vertical (channels) by 4 horizontal (OA BA OA BA)\n",
    "    fig, axs = plt.subplots(n_indices, 4, figsize=(8*plot_base_dimension, plot_base_dimension*n_indices), sharey=True, tight_layout=True)\n",
    "\n",
    "    # top charts stipulated with titles\n",
    "    axs[0][0].scatter(da_oa1[0], da_depth1, marker=',', s=1., color='k'); axs[0][0].set(ylim = (200., 0.), xlim = (0, 42), title='optical absorption with depth (midnight profile)')\n",
    "    axs[0][1].scatter(da_ba1[0], da_depth1, marker=',', s=1., color='r'); axs[0][1].set(ylim = (200., 0.), xlim = (0., 1.), title='beam attenuation with depth')\n",
    "    axs[0][2].scatter(da_oa2[0], da_depth2, marker=',', s=1., color='b'); axs[0][2].set(ylim = (200., 0.), xlim = (0, 42), title='optical absorption with depth (noon profile)')\n",
    "    axs[0][3].scatter(da_ba2[0], da_depth2, marker=',', s=1., color='g'); axs[0][3].set(ylim = (200., 0.), xlim = (0., 1.), title='beam attenuation with depth')\n",
    "\n",
    "    # subsequent charts have no titles\n",
    "    for i in range(1, n_indices):\n",
    "        axs[i][0].scatter(da_oa1[i], da_depth1, marker=',', s=1., color='k'); axs[i][0].set(ylim = (200., 0.), xlim = (0, 42))\n",
    "        axs[i][1].scatter(da_ba1[i], da_depth1, marker=',', s=1., color='r'); axs[i][1].set(ylim = (200., 0.), xlim = (0., 1.))\n",
    "        axs[i][2].scatter(da_oa2[i], da_depth2, marker=',', s=1., color='b'); axs[i][2].set(ylim = (200., 0.), xlim = (0, 42))\n",
    "        axs[i][3].scatter(da_ba2[i], da_depth2, marker=',', s=1., color='g'); axs[i][3].set(ylim = (200., 0.), xlim = (0., 1.))\n",
    "\n",
    "    fig.savefig('/data/rca/spectrophotometer/OSBSP_2019_' + month_str + '_' + day_str + '.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# I believe the dim swap is not nec; test this\n",
    "ds_press = ds_ascent1.swap_dims({'time':'int_ctd_pressure'})         # pressures for the midnight ascent\n",
    "\n",
    "# decimeter averages\n",
    "depth_start, depth_end, depth_delta = 5., 200., 0.2\n",
    "test_depth, test_ba = [], []\n",
    "\n",
    "# looping through pressures, where() to focus on a particular range, average BA\n",
    "for p in np.arange(depth_start, depth_end, depth_delta):\n",
    "    test0 = ds_press.where(ds_press.int_ctd_pressure > p, drop=True)                                  \n",
    "    test1 = test0.where(test0.int_ctd_pressure < p + depth_delta, drop=True).beam_attenuation.mean(axis=0, skipna=True)                                                            \n",
    "    this_spectrum = [float(test1[i]) for i in range(86)]                                               \n",
    "    test_ba.append(this_spectrum)                          # list of 86 appended to [test_ba]\n",
    "    test_depth.append(p + depth_delta/2.)                  # records center of this depth bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy for noon: Notice '2' in source and '_noon' in results\n",
    "ds_press = ds_ascent2.swap_dims({'time':'int_ctd_pressure'})         # pressures for the midnight ascent\n",
    "\n",
    "# decimeter averages\n",
    "depth_start, depth_end, depth_delta = 5., 200., 0.2\n",
    "test_depth_noon, test_ba_noon = [], []\n",
    "\n",
    "# looping through pressures, where() to focus on a particular range, average BA\n",
    "for p in np.arange(depth_start, depth_end, depth_delta):\n",
    "    test0 = ds_press.where(ds_press.int_ctd_pressure > p, drop=True)                                  \n",
    "    test1 = test0.where(test0.int_ctd_pressure < p + depth_delta, drop=True).beam_attenuation.mean(axis=0, skipna=True)                                                            \n",
    "    this_spectrum = [float(test1[i]) for i in range(86)]                                               \n",
    "    test_ba_noon.append(this_spectrum)                          # list of 86 appended to [test_ba]\n",
    "    test_depth_noon.append(p + depth_delta/2.)                  # records center of this depth bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ba_noon[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_xpose = list(map(list, zip(*test_ba)))\n",
    "test_xpose_noon = list(map(list, zip(*test_ba_noon)))\n",
    "# test_xpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(36,18), tight_layout=True)\n",
    "for i in range(9): \n",
    "    axs[0].plot(test_xpose[2 + 10*i], test_depth,  marker='^', color='r'); \n",
    "    axs[0].set(xlim = (.0, .6), ylim = (200., 0.), title='beam attenuation midnight')\n",
    "    axs[1].plot(test_xpose_noon[2 + 10*i], test_depth_noon,  marker='o', color='g'); \n",
    "    axs[1].set(xlim = (.0, .6), ylim = (200., 0.), title='beam attenuation noon')\n",
    "\n",
    "# Reference scatters from the source data: Using index 1 here is index 12 on the 0 -- 85 wavelength range; so \"blueish\"\n",
    "axs[0].scatter(da_ba1[1], da_depth1, marker=',', s=1., color='b'); \n",
    "axs[1].scatter(da_ba2[1], da_depth2, marker=',', s=1., color='k'); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_xpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_xpose[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_xpose[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.savefig('BA_midnight_and_noon_ascents_2019_01_01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work: plt.savefig('tmp0.png')\n",
    "fig.savefig('BA_midnight_and_noon_ascents_2019_01_01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls *.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ./images/misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<BR>\n",
    "<img src=\"./BA_midnight_and_noon_ascents_2019_01_01.png\" style=\"float: left;\" alt=\"drawing\" width=\"1800\"/>\n",
    "<div style=\"clear: left\">\n",
    "<BR>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ba_midnight_ascent.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(test_xpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ba_noon_ascent.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(test_xpose_noon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "test_data1, type(test_data1), test_data1.mean().values\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8,4), tight_layout=True)\n",
    "axs[0].scatter(da_oa1[0].time,  da_depth1, marker=',', s=1., color='k'); axs[0].set(ylim = (200., 0.), title='depth against time')\n",
    "axs[1].scatter(da_oa2[0].time,  da_depth2, marker=',', s=1., color='r'); axs[1].set(ylim = (200., 0.), title='depth against time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1.int_ctd_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in np.arange(depth_start, depth_end, depth_delta): \n",
    "#     print(ds_press.where(ds_press.int_ctd_pressure < d + depth_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate shallow profiler depth range for the above spectrophotometer data\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8,4), tight_layout=True)\n",
    "axs[0].scatter(da_oa1[0].time,  da_depth1, marker=',', s=1., color='k'); axs[0].set(ylim = (200., 0.), title='depth against time')\n",
    "axs[1].scatter(da_oa2[0].time,  da_depth2, marker=',', s=1., color='r'); axs[1].set(ylim = (200., 0.), title='depth against time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlined this to only one channel; else it takes forever\n",
    "n_bins = 200\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,4), sharey=True, tight_layout=True)\n",
    "axs[0].hist(da_oa1[0], bins=n_bins)\n",
    "axs[1].hist(da_oa2[0], bins=n_bins)\n",
    "\n",
    "noddy = axs[0].set_title('midnight optical absorption \\n histogram oddly quantized')\n",
    "noddy = axs[1].set_title('noon optical absorption \\n contrast data distribution at left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## work boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# ds_phsen = xr.open_dataset(data_dir + 'rca/simpler/osb_sp_phsen_2019.nc')\n",
    "# ds_ctdpf = xr.open_dataset(data_dir + 'rca/simpler/osb_sp_ctdpf_2019.nc')\n",
    "# ds_parad = xr.open_dataset(data_dir + 'rca/simpler/osb_sp_parad_2019.nc')\n",
    "# ds_spkir = xr.open_dataset(data_dir + 'rca/simpler/osb_sp_spkir_2019.nc')\n",
    "# ds_flort = xr.open_dataset(data_dir + 'rca/simpler/osb_sp_flort_2019.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth - Conductivity - Temperature + Dissolved Oxygen (`ctdpf`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sample per second for 23 million\n",
    "ds_ctdpf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on CTD: left off here\n",
    "\n",
    "* scan depth for profile start and stop times for the entire range\n",
    "\n",
    "skeleton code\n",
    "\n",
    "```\n",
    "profiles = []\n",
    "time_marker = dt64('2019-01-01T00:00:00.00')\n",
    "time_delta = td64(20 minutes)\n",
    "end_time = ds_ctdpf.time[-1]\n",
    "while time_marker < end_time:\n",
    "    note the current depth and time\n",
    "    next_time = time_marker + time_delta\n",
    "    is the depth considerably less compared to a threshold?\n",
    "        iterate a bit: three possibilities: The ascent started before time_marker, between, or after end_time\n",
    "        Now search forward to the apex...\n",
    "            Now search forward to the return\n",
    "    next while\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Irradiance (`spkir`)\n",
    "\n",
    "\n",
    "* 9 months continuous operation at about 4 samples per second gives 91 million samples\n",
    "* DataSet includes `int_ctd_pressure` and `time` Coordinates; Dimensions are `spectra` (0--7) and `time`\n",
    "* Data Variables: Only one, `spkir_downwelling_vector` which is (`time` x `spectra`)\n",
    "* Attributes include\n",
    "    * `node : SF01A`\n",
    "    * `id : RS01SBPS-SF01A-3D-SPKIRA101-streamed-spkir_data_record`\n",
    "    * `geospatial_lat_min : 44.52897`\n",
    "    * `geospatial_lon_min :-125.38966`\n",
    "\n",
    "\n",
    "\n",
    "From [Interactive Oceans](https://interactiveoceans.washington.edu/instruments/spectral-irradiance-sensor/): \n",
    "\n",
    "\n",
    "\n",
    "> The Spectral Irradiance sensor (Satlantic OCR-507 multispectral radiometer) measures the amount of downwelling radiation (light energy) \n",
    "per unit area that reaches a surface. Radiation is measured and reported separately for a series of seven wavelength bands (412, 443, \n",
    "490, 510, 555, 620, and 683nm), each between 10-20 nm wide. These measurements depend on the natural illumination conditions of sunlight \n",
    "and measure apparent optical properties. These measurements also are used as proxy measurements of important biogeochemical variables \n",
    "in the ocean.\n",
    ">\n",
    ">Spectral Irradiance sensors are installed on the  Science Pods on the Shallow Profiler Moorings at Axial Base (SF01A), Slope Base (SF01A),\n",
    "and at the Endurance Array Offshore (SF01B) sites. Instruments on the Cabled Array are provided by Satlantic – OCR-507. The profiling science \n",
    "pods have made >30,000 profiles since 2015. They are recovered and replaced annually using a remotely operated vehicle.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As it stands after a cursory set-up the plots show an overlay of about two and one half profile runs.\n",
    "\n",
    "\n",
    "### left off here\n",
    "\n",
    "* finish the CTD profile characterization in the prior section\n",
    "* write that as a file\n",
    "* read it here so we are not passing down data structures so much\n",
    "* use the timestamps to re-do the charts\n",
    "* look up the spectra specs\n",
    "* Any SME? What is spectral irradiance anyways? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = ds_spkir.sel(time=slice(dt64('2019-01-01T00:00'), dt64('2019-01-01T06:00:00')))     # first 6 hours of 2019: 86,000 values\n",
    "da_depth = ds.int_ctd_pressure.resample(time='1Min').mean()\n",
    "dsbar = ds.resample(time='1Min').mean()\n",
    "dsstd = ds.resample(time='1Min').std()                          # this takes about 14 minutes: Inefficient indexing across the spectra?\n",
    "# dsbar.spkir_downwelling_vector.isel(spectra=3).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_base_dimension = 4\n",
    "indices = [0, 1, 2, 3, 4, 5, 6]\n",
    "n_indices = len(indices)\n",
    "da_si, da_st = [], []                # averaged data (si = spectral irradiance) and corresponding standard deviations\n",
    "\n",
    "for idx in indices: \n",
    "    da_si.append(dsbar.spkir_downwelling_vector.isel(spectra=idx))\n",
    "    da_st.append(dsstd.spkir_downwelling_vector.isel(spectra=idx))\n",
    "\n",
    "fig, axs = plt.subplots(n_indices, 2, figsize=(4*plot_base_dimension, plot_base_dimension*n_indices), sharey=True, tight_layout=True)\n",
    "\n",
    "axs[0][0].scatter(da_si[0], da_depth, marker=',', s=1., color='k'); axs[0][0].set(ylim = (200., 0.), xlim = (-.03, .03), title='spectral irradiance averaged')\n",
    "axs[0][1].scatter(da_st[0], da_depth, marker=',', s=1., color='r'); axs[0][1].set(ylim = (200., 0.), xlim = (0., .002), title='standard deviation')\n",
    "\n",
    "for i in range(1, n_indices):\n",
    "    axs[i][0].scatter(da_si[i], da_depth, marker=',', s=1., color='k'); axs[i][0].set(ylim = (200., 0.), xlim = (-.03, .03))\n",
    "    axs[i][1].scatter(da_st[i], da_depth, marker=',', s=1., color='r'); axs[i][1].set(ylim = (200., 0.), xlim = (0., .002))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photosynthetically Active Radiation (`parad`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful result of this instrument is identifying profile time ranges. This is easily done *approximately* \n",
    "from the PAR data and can be done very *precisely* using depth data. This suggests a derived dataset of \n",
    "profile start / peak / end times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_parad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# artifact: Looking at PAR during shallow profiler rise/fall sequences\n",
    "\n",
    "# various views of PAR during profiles based on time selection\n",
    "t0, t1 = '2019-07-17T13', '2019-07-18T05'\n",
    "t0, t1 = '2019-07-17T18:40', '2019-07-17T19:40'\n",
    "t0, t1 = '2019-07-17T21', '2019-07-17T23:00'        # These are the nitrate profiles\n",
    "t0, t1 = '2019-07-18T21', '2019-07-18T23:00'\n",
    "t0, t1 = '2019-07-19T21', '2019-07-19T23:00'\n",
    "t0, t1 = '2019-07-17T18:40', '2019-07-17T19:40'     # These are the profiles prior to nitrate\n",
    "t0, t1 = '2019-07-18T18:40', '2019-07-18T19:40'\n",
    "t0, t1 = '2019-07-19T18:40', '2019-07-19T19:40'\n",
    "# da = ds_parad.sel(time=slice(t0, t1)).par_counts_output\n",
    "# p=da.plot.line(marker='o', figsize = (14,8), markersize=1, yincrease = True)\n",
    "\n",
    "# staged 'nitrate' profile compared with 'normal' profile\n",
    "t0, t1 = '2019-07-19T20:30', '2019-07-19T23:50'               # USE THIS!! This is a good nitrate profile time bracket\n",
    "t0, t1 = '2019-07-19T18:40', '2019-07-19T19:40'\n",
    "# da = ds_parad.sel(time=slice(t0, t1)).int_ctd_pressure\n",
    "# p=da.plot.line(marker='o', figsize = (14,8), markersize=1, yincrease = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluorometer (`flort`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Shallow Profiler fluorometers are 3-channel: chlorophyll, cdom and scattering\n",
    "* Deep profilers are 2-channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summer 2019 OSB SP using only fluor instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to get a check of the units for chlorophyll \n",
    "ds_flort.fluorometric_chlorophyll_a.units\n",
    "# p = rca_ds_chlor.fluorometric_chlorophyll_a.plot() is an option as well\n",
    "# by assigning the plot to p we have future ornamentation options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample and merge Datasets (mean and std)\n",
    "\n",
    "### Section de-activated! Can skip ahead...\n",
    "\n",
    "* We want to start with a copy of one `Dataset` (chosing `ctdpf`) as a starting point\n",
    "* One open question: If we re-sample to (say) minutes: Will minutes with no data produce skips? Or nan values? \n",
    "* Another question is whether to `.merge()` the data and then `.resample()` it using `mean()`; or vice versa\n",
    "  * For now I'll adopt vice versa\n",
    "\n",
    "### Part 1: Create a copy of the CTD + Oxygen dataset\n",
    "\n",
    "```\n",
    "%%time\n",
    "\n",
    "ds = ds_ctdpf.copy()\n",
    "ds = ds.reset_coords('seawater_pressure')        # converts the coordinate to a data variable\n",
    "```\n",
    "\n",
    "### Part 2: Merge in the fluorescence data\n",
    "\n",
    "```\n",
    "%%time \n",
    "\n",
    "ds = ds.merge(ds_flort)\n",
    "```\n",
    "\n",
    "### Part 3: Downsample to one minute intervals (in motion that's about 4 meters)\n",
    "\n",
    "```\n",
    "%%time\n",
    "ds_mean = ds.resample(time='1Min').mean()\n",
    "```\n",
    "\n",
    "\n",
    "### Part 4: Also get downsampled standard deviations\n",
    "\n",
    "This sort of thing can be really slow and it probably helps to break out / streamline types first.\n",
    "\n",
    "\n",
    "```\n",
    "%%time\n",
    "\n",
    "# expect 18 minutes\n",
    "ds_std  = ds.resample(time='1Min').std()\n",
    "```\n",
    "\n",
    "\n",
    "### Part 5: Write the results\n",
    "\n",
    "\n",
    "```\n",
    "%%time\n",
    "\n",
    "ds_mean.to_netcdf(data_dir + '/rca/simpler2/osb_sp_2019_ctdpf_flort_1Min_mean.nc')\n",
    "ds_std.to_netcdf(data_dir + '/rca/simpler2/osb_sp_2019_ctdpf_flort_1Min_std.nc')\n",
    "```\n",
    "\n",
    "###  This approach does resampling prior to merge but was taking way too long for some reason...\n",
    "\n",
    "```\n",
    "%%time\n",
    "\n",
    "ds = ds_flort.copy()\n",
    "ds\n",
    "ds = ds.reset_coords('seawater_pressure')        # converts the coordinate to a data variable\n",
    "sys.stdout.write('\\r'+'reset coordinates completed'\n",
    "ds_mean = ds.resample(time='1Min').mean()\n",
    "sys.stdout.write('\\r'+'resample with mean() completed'\n",
    "ds_std  = ds.resample(time='1Min').std()\n",
    "sys.stdout.write('\\r'+'resample with std() completed'\n",
    "```\n",
    "\n",
    "## Load R/M Dataset ctdpf + flort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# This failed when tried 9/2020...\n",
    "\n",
    "ds_mean = xr.open_dataset(data_dir + '/rca/simpler2/osb_sp_2019_ctdpf_flort_1Min_mean.nc')\n",
    "ds_std  = xr.open_dataset(data_dir + '/rca/simpler2/osb_sp_2019_ctdpf_flort_1Min_std.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine selected mean / standard deviation noon profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nplots = 20\n",
    "\n",
    "p,a = plt.subplots(nplots, 1, figsize=(16,nplots*8))\n",
    "\n",
    "a[0].set(ylim = (200., 0.), title='depth(time)')\n",
    "a[2].set(ylim = (35., 29.), title='salinity(time)')\n",
    "a[4].set(ylim = (200., 0.), xlim = ( 0.0006, 0.00065), title='SSC(depth)')\n",
    "a[6].set(ylim = (200., 0.), xlim = (29.    , 35.    ), title='salinity(depth)')\n",
    "a[8].set(ylim = (200., 0.), xlim = ( 6.    , 20.    ), title='temperature(depth)')\n",
    "a[10].set(ylim = (200., 0.), xlim = (60.    , 320.   ), title='dissolved oxygen(depth)')\n",
    "a[12].set(ylim = (200., 0.), xlim = ( 0.    , 3.     ), title='chlorophyll(depth)')\n",
    "a[14].set(ylim = (200., 0.), xlim = ( 0.5   , 2.5    ), title='cdom(depth)')\n",
    "a[16].set(ylim = (200., 0.), xlim = ( 0.0   , 0.0005 ), title='TVSC(depth)')\n",
    "a[18].set(ylim = (200., 0.), xlim = ( 0.0   , 0.003  ), title='optical backscatter(depth)')\n",
    "\n",
    "a[1].set( ylim = (  3., 0.),                                title='std depth(time)')\n",
    "a[3].set( ylim = (  3., 0.),                                title='std salinity(time)')\n",
    "a[5].set( ylim = (200., 0.), xlim = ( 0.0    ,  0.0000015), title='std SSC(depth)')\n",
    "a[7].set( ylim = (200., 0.), xlim = ( 0.0    ,  0.25     ), title='std salinity(depth)')\n",
    "a[9].set( ylim = (200., 0.), xlim = ( 0.0    ,  1.0      ), title='std temperature(depth)')\n",
    "a[11].set(ylim = (200., 0.), xlim = ( 0.0    , 15.       ), title='std dissolved oxygen(depth)')\n",
    "a[13].set(ylim = (200., 0.), xlim = ( 0.0    ,  1.5      ), title='std chlorophyll(depth)')\n",
    "a[15].set(ylim = (200., 0.), xlim = ( 0.0    , .50       ), title='std cdom(depth)')\n",
    "a[17].set(ylim = (200., 0.), xlim = ( 0.0    , 0.001     ), title='std TVSC(depth)')\n",
    "a[19].set(ylim = (200., 0.), xlim = ( 0.0    , 0.01      ), title='std optical backscatter(depth)')\n",
    "\n",
    "for monthstring in ['01', '02', '03', '04', '05', '06', '07', '08', '09']:\n",
    "    for daystring in ['01', '15']:\n",
    "        datestring0 = '2019-' + monthstring + '-' + daystring + 'T08:30' \n",
    "        datestring1 = '2019-' + monthstring + '-' + daystring + 'T11:50' \n",
    "        ds1 = ds_mean.sel(time=slice(datestring0, datestring1))\n",
    "        a[0].plot(ds1.time.values, ds1.seawater_pressure)\n",
    "        a[2].plot(ds1.time.values, ds1.practical_salinity)\n",
    "        a[4].plot(ds1.seawater_scattering_coefficient, ds1.seawater_pressure)\n",
    "        a[6].plot(ds1.practical_salinity, ds1.seawater_pressure)\n",
    "        a[8].plot(ds1.seawater_temperature, ds1.seawater_pressure)\n",
    "        a[10].plot(ds1.corrected_dissolved_oxygen, ds1.seawater_pressure)\n",
    "        a[12].plot(ds1.fluorometric_chlorophyll_a, ds1.seawater_pressure)\n",
    "        a[14].plot(ds1.fluorometric_cdom, ds1.seawater_pressure)\n",
    "        a[16].plot(ds1.total_volume_scattering_coefficient, ds1.seawater_pressure)\n",
    "        a[18].plot(ds1.optical_backscatter, ds1.seawater_pressure)\n",
    "        \n",
    "        ds2 = ds_std.sel(time=slice(datestring0, datestring1))\n",
    "        a[1].plot(ds2.time.values, ds2.seawater_pressure)\n",
    "        a[3].plot(ds2.time.values, ds2.practical_salinity)\n",
    "        a[5].plot(ds2.seawater_scattering_coefficient, ds1.seawater_pressure)\n",
    "        a[7].plot(ds2.practical_salinity, ds1.seawater_pressure)\n",
    "        a[9].plot(ds2.seawater_temperature, ds1.seawater_pressure)\n",
    "        a[11].plot(ds2.corrected_dissolved_oxygen, ds1.seawater_pressure)\n",
    "        a[13].plot(ds2.fluorometric_chlorophyll_a, ds1.seawater_pressure)\n",
    "        a[15].plot(ds2.fluorometric_cdom, ds1.seawater_pressure)\n",
    "        a[17].plot(ds2.total_volume_scattering_coefficient, ds1.seawater_pressure)\n",
    "        a[19].plot(ds2.optical_backscatter, ds1.seawater_pressure)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nplots = 12\n",
    "p,a = plt.subplots(12, 1, figsize=(10,nplots*6))\n",
    "\n",
    "lim_salinity_lo,    lim_salinity_hi    = 29.5, 34.5\n",
    "lim_temperature_lo, lim_temperature_hi =  6.,  20.\n",
    "lim_do_lo,          lim_do_hi          =  0.,  100.\n",
    "lim_chlor_lo,       lim_chlor_hi       = -0.2,  1.5\n",
    "lim_cdom_lo,        lim_cdom_hi        =  0.,   1.8\n",
    "lim_backscatt_lo,   lim_backscatt_hi   =  0.,   0.004\n",
    "\n",
    "a[10].scatter(ds1.time,             ds.salinity,                                     color='b',               marker='o', s=36.)\n",
    "a[11].scatter(time,             sample_count,                              color='r',               marker='o', s=36.)\n",
    "\n",
    "a[0].set(ylim = (250., 0.), xlim = (lim_salinity_lo, lim_salinity_hi),               title='salinity distribution with depth')\n",
    "a[1].set(ylim = (250., 0.), xlim = (lim_temperature_lo, lim_temperature_hi),         title='temperature distribution with depth')\n",
    "a[2].set(ylim = (250., 0.), xlim = (lim_chlor_lo, lim_chlor_hi),                     title='chlorophyll distribution with depth')\n",
    "a[3].set(ylim = (250., 0.), xlim = (lim_cdom_lo, lim_cdom_hi),                       title='cdom distribution with depth')\n",
    "a[4].set(ylim = (250., 0.), xlim = (lim_backscatt_lo, lim_backscatt_hi),             title='backscatter distribution with depth')\n",
    "a[5].set(ylim = (lim_salinity_lo, lim_salinity_hi),                                  title='salinity distribution with time')\n",
    "a[6].set(ylim = (lim_temperature_lo, lim_temperature_hi),                            title='temperature distribution with time')\n",
    "a[7].set(ylim = (lim_chlor_lo, lim_chlor_hi),                                        title='chlorophyll distribution with time')\n",
    "a[8].set(ylim = (lim_cdom_lo, lim_cdom_hi),                                          title='cdom distribution with time')\n",
    "a[9].set(ylim = (lim_backscatt_lo, lim_backscatt_hi),                                title='backscatter distribution with time')\n",
    "a[10].set(ylim=(250., 0.), xlim = (time[0] - td64(1, 'D'), time[-1] + td64(1, 'D')), title='Distribution of depths with time')\n",
    "a[11].set(xlim = (time[0] - td64(1, 'D'), time[-1] + td64(1, 'D')),                  title='Distribution of sample counts with time')\n",
    "\n",
    "# a[0].plot(modis_da_chlor.time, modis_da_chlor, color='r', marker='D', markersize = 9., linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some 'where next?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously these data are noisier towards the surface and some are ridiculously noisy. The next \n",
    "step needed is to filter on standard deviation, say using a threshold, to determine if throwing \n",
    "out a certain amount of the clutter leaves a signal of interest. The fluorometer is particularly\n",
    "troublesome. \n",
    "\n",
    "\n",
    "Meanwhile it will be interesting to revisit curtain plots now that we are at one minute intervals. \n",
    "\n",
    "\n",
    "There is also the notion of reducing depth profiles to simple metrics.\n",
    "\n",
    "... ideas ...\n",
    "\n",
    "\n",
    "* profile start, peak, end times\n",
    "* platform residence: start and end times (from profile times)\n",
    "\n",
    "\n",
    "* (smoothed) chlorophyll derivative, curvature, rate of curvature\n",
    "* Similarly salinity seems to go through a consistent double-zero in rate of curvature\n",
    "\n",
    "* intersection depth as used in TDR; for example for temperature or salinity\n",
    "  * extrapolate smoothed pressure by backing off the derivative change\n",
    "  * extrapolate platform, intersect\n",
    "\n",
    "* time of day / sun angle\n",
    "* local time\n",
    "* rate of ascent verify; I think 300 cm / minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curtain plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Was 10 minutes at full resolution prior to resample\n",
    "\n",
    "\n",
    "t0 = dt64('2019-05-01T00:00')                \n",
    "t1 = dt64('2019-09-28T00:00')\n",
    "\n",
    "nPlots = 8\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "p,a = plt.subplots(nPlots, 1, figsize=(18, 5*nPlots))\n",
    "\n",
    "nTemp = mplcolors.Normalize(vmin=8.,vmax=14.)\n",
    "nChlor = mplcolors.Normalize(vmin=0.3,vmax=0.8)\n",
    "nSal = mplcolors.Normalize(vmin=32,vmax=34)\n",
    "nCDO = mplcolors.Normalize(vmin=100,vmax=250)\n",
    "nCdom = mplcolors.Normalize(vmin=1.0,vmax=2.0)\n",
    "nTVSC = mplcolors.Normalize(vmin=0.00008,vmax=0.00035)\n",
    "nSSC = mplcolors.Normalize(vmin=0.00062,vmax=0.00064)\n",
    "nBack = mplcolors.Normalize(vmin=0.0005,vmax=0.0020)\n",
    "\n",
    "swp = ds_mean.seawater_pressure\n",
    "\n",
    "\n",
    "# ['thermal', 'haline', 'solar', 'ice', 'gray', 'oxy', 'deep', 'dense', 'algae', 'matter', 'turbid',\n",
    "#  'speed', 'amp', 'tempo', 'rain', 'phase', 'topo', 'balance', 'delta', 'curl', 'diff', 'tarn']\n",
    "\n",
    "a[0].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.thermal, c=ds_mean.seawater_temperature,                marker= ',', s = 9.0, norm=nTemp)\n",
    "a[1].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.algae,   c=ds_mean.fluorometric_chlorophyll_a,          marker= ',', s = 9.0, norm=nChlor)\n",
    "a[2].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.haline,  c=ds_mean.practical_salinity,                  marker= ',', s = 9.0, norm=nSal)\n",
    "a[3].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.oxy,     c=ds_mean.corrected_dissolved_oxygen,          marker= ',', s = 9.0, norm=nCDO)\n",
    "a[4].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.matter,  c=ds_mean.fluorometric_cdom,                   marker= ',', s = 9.0, norm=nCdom)\n",
    "a[5].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.ice,     c=ds_mean.total_volume_scattering_coefficient, marker= ',', s = 9.0, norm=nTVSC)\n",
    "a[6].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.solar,   c=ds_mean.seawater_scattering_coefficient,     marker= ',', s = 9.0, norm=nSSC)\n",
    "a[7].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.delta,   c=ds_mean.optical_backscatter,                 marker= ',', s = 9.0, norm=nBack)\n",
    "\n",
    "for i in range(nPlots):\n",
    "    a[i].set(ylim=(100., 0.0), xlim = (t0, t1))\n",
    "\n",
    "a[0].set(title='temperature')\n",
    "a[1].set(title='chlorophyll')\n",
    "a[2].set(title='salinity')\n",
    "a[3].set(title='dissolved oxygen')\n",
    "a[4].set(title='CDOM')\n",
    "a[5].set(title='TVSC')\n",
    "a[6].set(title='SSC')\n",
    "a[7].set(title='backscatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds_mean.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-writing Curtain Plotter as a function (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# Also include colorbars!\n",
    "\n",
    "for key in ds.data_vars: \n",
    "    if key not in keep_data_vars: ds = ds.drop(key)\n",
    "\n",
    "def curtains(timerange, ds, norms, depth, cmaps, skip):\n",
    "    nPlots = len(ds.data_vars) - len(skip)\n",
    "    for key in ds.data_vars: \n",
    "        if key not in skip:\n",
    "            \n",
    "\n",
    "\n",
    "t0 = dt64('2019-05-01T00:00')                \n",
    "t1 = dt64('2019-09-28T00:00')\n",
    "\n",
    "nPlots = 8\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "p,a = plt.subplots(nPlots, 1, figsize=(18, 5*nPlots))\n",
    "\n",
    "nTemp = mplcolors.Normalize(vmin=8.,vmax=14.)\n",
    "nChlor = mplcolors.Normalize(vmin=0.3,vmax=0.8)\n",
    "nSal = mplcolors.Normalize(vmin=32,vmax=34)\n",
    "nCDO = mplcolors.Normalize(vmin=100,vmax=250)\n",
    "nCdom = mplcolors.Normalize(vmin=1.0,vmax=2.0)\n",
    "nTVSC = mplcolors.Normalize(vmin=0.00008,vmax=0.00035)\n",
    "nSSC = mplcolors.Normalize(vmin=0.00062,vmax=0.00064)\n",
    "nBack = mplcolors.Normalize(vmin=0.0005,vmax=0.0020)\n",
    "\n",
    "swp = ds_mean.seawater_pressure\n",
    "\n",
    "\n",
    "# ['thermal', 'haline', 'solar', 'ice', 'gray', 'oxy', 'deep', 'dense', 'algae', 'matter', 'turbid',\n",
    "#  'speed', 'amp', 'tempo', 'rain', 'phase', 'topo', 'balance', 'delta', 'curl', 'diff', 'tarn']\n",
    "\n",
    "a[0].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.thermal, c=ds_mean.seawater_temperature,                marker= ',', s = 9.0, norm=nTemp)\n",
    "a[1].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.algae,   c=ds_mean.fluorometric_chlorophyll_a,          marker= ',', s = 9.0, norm=nChlor)\n",
    "a[2].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.haline,  c=ds_mean.practical_salinity,                  marker= ',', s = 9.0, norm=nSal)\n",
    "a[3].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.oxy,     c=ds_mean.corrected_dissolved_oxygen,          marker= ',', s = 9.0, norm=nCDO)\n",
    "a[4].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.matter,  c=ds_mean.fluorometric_cdom,                   marker= ',', s = 9.0, norm=nCdom)\n",
    "a[5].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.ice,     c=ds_mean.total_volume_scattering_coefficient, marker= ',', s = 9.0, norm=nTVSC)\n",
    "a[6].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.solar,   c=ds_mean.seawater_scattering_coefficient,     marker= ',', s = 9.0, norm=nSSC)\n",
    "a[7].scatter(ds_mean.time.values, swp, cmap=cmocean.cm.delta,   c=ds_mean.optical_backscatter,                 marker= ',', s = 9.0, norm=nBack)\n",
    "\n",
    "for i in range(nPlots):\n",
    "    a[i].set(ylim=(100., 0.0), xlim = (t0, t1))\n",
    "\n",
    "a[0].set(title='temperature')\n",
    "a[1].set(title='chlorophyll')\n",
    "a[2].set(title='salinity')\n",
    "a[3].set(title='dissolved oxygen')\n",
    "a[4].set(title='CDOM')\n",
    "a[5].set(title='TVSC')\n",
    "a[6].set(title='SSC')\n",
    "a[7].set(title='backscatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colorbars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Was 10 minutes at full resolution prior to resample\n",
    "\n",
    "# ['thermal', 'haline', 'solar', 'ice', ...]\n",
    "\n",
    "\n",
    "t0 = dt64('2019-01-01T00:00')                \n",
    "t1 = dt64('2019-04-01T00:00')\n",
    "\n",
    "nPlots = 2\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "norm_temp = mplcolors.Normalize(vmin=8.,vmax=12.)\n",
    "norm_chlor = mplcolors.Normalize(vmin=0.3,vmax=0.8)\n",
    "\n",
    "p,a=plt.subplots(nPlots, 1, figsize=(18,5*nPlots))\n",
    "\n",
    "im0 = a[0].scatter(ds_mean.time.values, ds_mean.seawater_pressure, cmap=cmocean.cm.thermal, c=ds_mean.seawater_temperature, \\\n",
    "             marker= ',', s = 9.0, norm=norm_temp)\n",
    "im1 = a[1].scatter(ds_mean.time.values, ds_mean.seawater_pressure, cmap=cmocean.cm.haline, c=ds_mean.fluorometric_chlorophyll_a, \\\n",
    "             marker= ',', s = 9.0, norm=norm_chlor)\n",
    "\n",
    "a[0].set(ylim=(100., 0.0), xlim = (t0, t1), title='temperature')\n",
    "a[1].set(ylim=(100., 0.0), xlim = (t0, t1), title='chlorophyll')\n",
    "\n",
    "\n",
    "cax0 = p.add_axes([0.60, 0.904, 0.26, 0.015])\n",
    "cax1 = p.add_axes([0.60, 0.492, 0.26, 0.015])\n",
    "p.colorbar(im0, cax=cax0, orientation='horizontal')\n",
    "p.colorbar(im1, cax=cax1, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oregon Slope Base Shallow Profiler near-surface comparison to MODIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Oregon Slope Base site has a depth of about 2900 meters and is located at the base of the continental shelf \n",
    "west of Oregon. The fluorometer data are collected over the course of a day as nine profile runs from a depth\n",
    "of 200 meters to near the surface. Between profiles that profiler pod is at rest on a platform that is always\n",
    "at a depth of 200 meters. The sampling rate is a little less than on sample per second. \n",
    "\n",
    "\n",
    "The objective in this section is to create an approximate record of near-surface chlorophyll (all measurements \n",
    "above say 25 meter depth) and compare that with the MODIS values for the same site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_flort.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion: doy from datetime64 and datetime64 from (year + doy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('As dates: The 2019 data has start:', ds_mean.time[0].values, 'to end:', ds_mean.time[-1].values)\n",
    "      \n",
    "      \n",
    "# Note use of .values to get the actual datetime64 from the time coordinate\n",
    "doy0 = doy(ds_mean.time[0].values)\n",
    "doy1 = doy(ds_mean.time[-1].values)\n",
    "print('\\nThis dataset runs from day', doy0, 'to day', doy1, 'for a span in days of', doy1 - doy0 + 1)\n",
    "\n",
    "# Make sure 1-JAN works out properly in the other direction\n",
    "print(\"\\nThe date corresponding to 2019 doy = 1 is\", dt64_from_doy(2019, 1))\n",
    "\n",
    "inter_sample_time = (ds_mean.time[1].values - ds_mean.time[0].values)/td64(1, 's')\n",
    "print('\\nThe time between one-minute (resampled) timestamps is of course', inter_sample_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early work on SP Fluorometer data reduction (summer 2019 only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hey seriously look at salinity and picture a chart of the second derivative of a filtered version. That chart will cross zero twice and the zero crossings could be seen as a characterization of the upper layer.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# \n",
    "# Shallow profiler data reduction\n",
    "# \n",
    "# From time series we would like to progress to time-block values, for example considering six-day\n",
    "#   blocks of time throughout the year. There are three criteria for creating a value for some \n",
    "#   sensor parameter such as chlorophyll-a: There are samples in a depth range and in a time range;\n",
    "#   and the mean of these values is substantial when compared to their standard deviation.\n",
    "\n",
    "# operate on rca_ds_chlor to extract values for a year: Average by week and depth\n",
    "doy = 164                 # one would eventually make this 0\n",
    "doy_end = 257             # one would eventually make this 365\n",
    "year = 2019\n",
    "depth_start, depth_end, depth_delta = 0., 260.1, 10.\n",
    "time_interval_days = 1     # even makes the \"center of interval\" simpler\n",
    "\n",
    "time = []\n",
    "depth = []\n",
    "sample_count = []\n",
    "salinity = []\n",
    "temperature = []\n",
    "chlor = []\n",
    "cdom = []\n",
    "backscatt = []\n",
    "\n",
    "lim_temperature_ignore = 2.0\n",
    "lim_salinity_ignore    = 1.0\n",
    "lim_chlor_ignore       = 0.6\n",
    "lim_cdom_ignore        = 0.8\n",
    "lim_backscatt_ignore   = 0.0015\n",
    "\n",
    "while doy < doy_end:\n",
    "    \n",
    "    print('day of year', doy)\n",
    "\n",
    "    time_range_start = dt64(str(year) + '-01-01') + td64(doy, 'D')\n",
    "    time_range_end   = dt64(str(year) + '-01-01') + td64(doy + time_interval_days, 'D')    \n",
    "    this_time        = dt64(str(year) + '-01-01') + td64(doy + time_interval_days//2, 'D')\n",
    "    \n",
    "    ds1 = rca_ds_chlor.sel(time = slice(time_range_start, time_range_end))\n",
    "    \n",
    "    for d in np.arange(depth_start, depth_end, depth_delta): \n",
    "        \n",
    "        this_depth = d + depth_delta/2.\n",
    "        \n",
    "        ds2 = ds1.where(ds1.int_ctd_pressure <  d + depth_delta, drop=True)\n",
    "        ds3 = ds2.where(ds2.int_ctd_pressure >= d,               drop=True)\n",
    "\n",
    "        nSamples = ds3.dims['time']\n",
    "        sample_count.append(nSamples)     \n",
    "        depth.append(this_depth)\n",
    "        time.append(this_time)  \n",
    "            \n",
    "        if nSamples > 1:\n",
    "   \n",
    "            param_mean = ds3.practical_salinity.values.mean()\n",
    "            param_std = ds3.practical_salinity.values.std()\n",
    "            if param_std < lim_salinity_ignore: salinity.append((param_mean, param_std, this_depth, this_time, nSamples))\n",
    "                \n",
    "            param_mean = ds3.seawater_temperature.values.mean()\n",
    "            param_std = ds3.seawater_temperature.values.std()\n",
    "            if param_std < lim_temperature_ignore: temperature.append((param_mean, param_std, this_depth, this_time, nSamples))\n",
    "\n",
    "            param_mean = ds3.fluorometric_chlorophyll_a.values.mean()\n",
    "            param_std = ds3.fluorometric_chlorophyll_a.values.std()\n",
    "            if param_std < lim_chlor_ignore: chlor.append((param_mean, param_std, this_depth, this_time, nSamples))\n",
    "                \n",
    "            param_mean = ds3.fluorometric_cdom.values.mean()\n",
    "            param_std = ds3.fluorometric_cdom.values.std()\n",
    "            if param_std < lim_cdom_ignore: cdom.append((param_mean, param_std, this_depth, this_time, nSamples))\n",
    "\n",
    "            param_mean = ds3.optical_backscatter.values.mean()\n",
    "            param_std = ds3.optical_backscatter.values.std()\n",
    "            if param_std < lim_backscatt_ignore: backscatt.append((param_mean, param_std, this_depth, this_time, nSamples))\n",
    "        \n",
    "        else:\n",
    "            salinity.append((np.nan, np.nan, this_depth, this_time))\n",
    "            temperature.append((np.nan, np.nan, this_depth, this_time))\n",
    "            chlor.append((np.nan, np.nan, this_depth, this_time))\n",
    "            cdom.append((np.nan, np.nan, this_depth, this_time))\n",
    "            backscatt.append((np.nan, np.nan, this_depth, this_time))\n",
    "\n",
    "    # increment the day of year by one week\n",
    "    doy += time_interval_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nplots = 12\n",
    "p,a = plt.subplots(12, 1, figsize=(10,nplots*6))\n",
    "\n",
    "# plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "salinity_mean, salinity_std, salinity_depth, salinity_time             = zip(*salinity)\n",
    "temperature_mean, temperature_std, temperature_depth, temperature_time = zip(*temperature)\n",
    "chlor_mean, chlor_std, chlor_depth, chlor_time                         = zip(*chlor)\n",
    "cdom_mean, cdom_std, cdom_depth, cdom_time                             = zip(*cdom)\n",
    "backscatt_mean, backscatt_std, backscatt_depth, backscatt_time         = zip(*backscatt)\n",
    "\n",
    "lim_salinity_lo,    lim_salinity_hi    = 29.5, 34.5\n",
    "lim_temperature_lo, lim_temperature_hi =  6.,  20.\n",
    "lim_chlor_lo,       lim_chlor_hi       = -0.2,  1.5\n",
    "lim_cdom_lo,        lim_cdom_hi        =  0.,   1.8\n",
    "lim_backscatt_lo,   lim_backscatt_hi   =  0.,   0.004\n",
    "\n",
    "a[0].errorbar(salinity_mean,    salinity_depth,    xerr = salinity_std,    color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[1].errorbar(temperature_mean, temperature_depth, xerr = temperature_std, color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[2].errorbar(chlor_mean,       chlor_depth,       xerr = chlor_std,       color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[3].errorbar(cdom_mean,        cdom_depth,        xerr = cdom_std,        color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[4].errorbar(backscatt_mean,   backscatt_depth,   xerr = backscatt_std,   color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[5].errorbar(salinity_time,    salinity_mean,     yerr = salinity_std,    color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[6].errorbar(temperature_time, temperature_mean,  yerr = temperature_std, color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[7].errorbar(chlor_time,       chlor_mean,        yerr = chlor_std,       color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[8].errorbar(cdom_time,        cdom_mean,         yerr = cdom_std,        color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[9].errorbar(backscatt_time,   backscatt_mean,    yerr = backscatt_std,   color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[10].scatter(time,             depth,                                     color='b',               marker='o', s=36.)\n",
    "a[11].scatter(time,             sample_count,                              color='r',               marker='o', s=36.)\n",
    "\n",
    "a[0].set(ylim = (250., 0.), xlim = (lim_salinity_lo, lim_salinity_hi),               title='salinity distribution with depth')\n",
    "a[1].set(ylim = (250., 0.), xlim = (lim_temperature_lo, lim_temperature_hi),         title='temperature distribution with depth')\n",
    "a[2].set(ylim = (250., 0.), xlim = (lim_chlor_lo, lim_chlor_hi),                     title='chlorophyll distribution with depth')\n",
    "a[3].set(ylim = (250., 0.), xlim = (lim_cdom_lo, lim_cdom_hi),                       title='cdom distribution with depth')\n",
    "a[4].set(ylim = (250., 0.), xlim = (lim_backscatt_lo, lim_backscatt_hi),             title='backscatter distribution with depth')\n",
    "a[5].set(ylim = (lim_salinity_lo, lim_salinity_hi),                                  title='salinity distribution with time')\n",
    "a[6].set(ylim = (lim_temperature_lo, lim_temperature_hi),                            title='temperature distribution with time')\n",
    "a[7].set(ylim = (lim_chlor_lo, lim_chlor_hi),                                        title='chlorophyll distribution with time')\n",
    "a[8].set(ylim = (lim_cdom_lo, lim_cdom_hi),                                          title='cdom distribution with time')\n",
    "a[9].set(ylim = (lim_backscatt_lo, lim_backscatt_hi),                                title='backscatter distribution with time')\n",
    "a[10].set(ylim=(250., 0.), xlim = (time[0] - td64(1, 'D'), time[-1] + td64(1, 'D')), title='Distribution of depths with time')\n",
    "a[11].set(xlim = (time[0] - td64(1, 'D'), time[-1] + td64(1, 'D')),                  title='Distribution of sample counts with time')\n",
    "\n",
    "# a[0].plot(modis_da_chlor.time, modis_da_chlor, color='r', marker='D', markersize = 9., linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-day resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nplots = 12\n",
    "p,a = plt.subplots(12, 1, figsize=(10,nplots*6))\n",
    "\n",
    "# plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "salinity_mean, salinity_std, salinity_depth, salinity_time             = zip(*salinity)\n",
    "temperature_mean, temperature_std, temperature_depth, temperature_time = zip(*temperature)\n",
    "chlor_mean, chlor_std, chlor_depth, chlor_time                         = zip(*chlor)\n",
    "cdom_mean, cdom_std, cdom_depth, cdom_time                             = zip(*cdom)\n",
    "backscatt_mean, backscatt_std, backscatt_depth, backscatt_time         = zip(*backscatt)\n",
    "\n",
    "lim_salinity_lo,    lim_salinity_hi    = 29.5, 34.5\n",
    "lim_temperature_lo, lim_temperature_hi =  6.,  20.\n",
    "lim_chlor_lo,       lim_chlor_hi       = -0.2,  1.5\n",
    "lim_cdom_lo,        lim_cdom_hi        =  0.,   1.8\n",
    "lim_backscatt_lo,   lim_backscatt_hi   =  0.,   0.004\n",
    "\n",
    "a[0].errorbar(salinity_mean,    salinity_depth,    xerr = salinity_std,    color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[1].errorbar(temperature_mean, temperature_depth, xerr = temperature_std, color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[2].errorbar(chlor_mean,       chlor_depth,       xerr = chlor_std,       color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[3].errorbar(cdom_mean,        cdom_depth,        xerr = cdom_std,        color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[4].errorbar(backscatt_mean,   backscatt_depth,   xerr = backscatt_std,   color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[5].errorbar(salinity_time,    salinity_mean,     yerr = salinity_std,    color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[6].errorbar(temperature_time, temperature_mean,  yerr = temperature_std, color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[7].errorbar(chlor_time,       chlor_mean,        yerr = chlor_std,       color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[8].errorbar(cdom_time,        cdom_mean,         yerr = cdom_std,        color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[9].errorbar(backscatt_time,   backscatt_mean,    yerr = backscatt_std,   color='k', ecolor = 'r', marker='^', capsize=4, linestyle='none')\n",
    "a[10].scatter(time,             depth,                                     color='b',               marker='o', s=36.)\n",
    "a[11].scatter(time,             sample_count,                              color='r',               marker='o', s=36.)\n",
    "\n",
    "a[0].set(ylim = (250., 0.), xlim = (lim_salinity_lo, lim_salinity_hi),               title='salinity distribution with depth')\n",
    "a[1].set(ylim = (250., 0.), xlim = (lim_temperature_lo, lim_temperature_hi),         title='temperature distribution with depth')\n",
    "a[2].set(ylim = (250., 0.), xlim = (lim_chlor_lo, lim_chlor_hi),                     title='chlorophyll distribution with depth')\n",
    "a[3].set(ylim = (250., 0.), xlim = (lim_cdom_lo, lim_cdom_hi),                       title='cdom distribution with depth')\n",
    "a[4].set(ylim = (250., 0.), xlim = (lim_backscatt_lo, lim_backscatt_hi),             title='backscatter distribution with depth')\n",
    "a[5].set(ylim = (lim_salinity_lo, lim_salinity_hi),                                  title='salinity distribution with time')\n",
    "a[6].set(ylim = (lim_temperature_lo, lim_temperature_hi),                            title='temperature distribution with time')\n",
    "a[7].set(ylim = (lim_chlor_lo, lim_chlor_hi),                                        title='chlorophyll distribution with time')\n",
    "a[8].set(ylim = (lim_cdom_lo, lim_cdom_hi),                                          title='cdom distribution with time')\n",
    "a[9].set(ylim = (lim_backscatt_lo, lim_backscatt_hi),                                title='backscatter distribution with time')\n",
    "a[10].set(ylim=(250., 0.), xlim = (time[0] - td64(1, 'D'), time[-1] + td64(1, 'D')), title='Distribution of depths with time')\n",
    "a[11].set(xlim = (time[0] - td64(1, 'D'), time[-1] + td64(1, 'D')),                  title='Distribution of sample counts with time')\n",
    "\n",
    "# a[0].plot(modis_da_chlor.time, modis_da_chlor, color='r', marker='D', markersize = 9., linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(chlor))\n",
    "print((256-164)*26)\n",
    "print(chlor[438])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .rolling().mean() to smooth a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rca_subda_chlor_rolling_mean = rca_subds_chlor.fluorometric_chlorophyll_a.rolling(time=600, center=True).mean()\n",
    "\n",
    "# minima version\n",
    "# rca_subda_chlor_rolling_min = rca_subds_chlor.fluorometric_chlorophyll_a.rolling(time=600).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart: MODIS and SP-surface chlorophyll superimposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "p,a = plt.subplots(3, 1, figsize=(12,18))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# alternative: use .plot(): a[0].plot(rca_subda_time, rca_subda_chlor_rolling_mean, color='b')\n",
    "a[0].scatter(rca_subda_time.values, rca_subda_chlor_rolling_mean, color='b', marker= 'o', s = 4.0)\n",
    "a[1].scatter(rca_subda_chlor_rolling_mean, rca_subda_pressure, color='k', marker= ',', s = 1.0) \n",
    "a[2].scatter(rca_subda_time.values, rca_subda_pressure, color='b', marker=',', s=1.0) \n",
    "\n",
    "a[0].set(ylim=(0., 1.5), xlim = (t0, t1), \\\n",
    "         title='OSB Chlorophyll (Summer 2019) \\n MODIS (red) vs shallow profiler at surface')\n",
    "a[1].set(ylim=(30., 0.), xlim = (0., 3.), title='shallow profiler: chlorophyll (x axis) vs pressure')\n",
    "a[2].set(ylim=(30., 0.), xlim = (t0, short_time), title='shallow profiler: time (x axis) vs pressure')\n",
    "\n",
    "a[0].plot(modis_da_chlor.time, modis_da_chlor, color='r', marker='D', markersize = 9., linestyle='dashed')\n",
    "# a[0].scatter(np.datetime(modis_da_chlor.time), modis_da_chlor, color='r', marker= ',', s = 36.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic exploration of time and Datasets (compression needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_ds_chlor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = dt64('2019-06-14T23:10')\n",
    "week_timedelta = td64(1,'W')\n",
    "day_timedelta = td64(1,'D')\n",
    "hour_timedelta = td64(1,'h')\n",
    "minute_timedelta = td64(1,'m')\n",
    "time_end = time_start + minute_timedelta\n",
    "# print (time_start, week_timedelta, time_end)\n",
    "# rca_subds_week = rca_ds_chlor.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_ds_chlor.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minute_data = rca_ds_chlor.time.where(rca_ds_chlor.time < time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minute_data = rca_ds_chlor.time[:100]\n",
    "# dict(time=slice(time_start, time_end))]\n",
    "time0 = dt64('2019-06-14T23:10:19.399109120')\n",
    "time1 = dt64('2019-06-14T23:12:11.132952064')\n",
    "# time1 = time0 + day_timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uses `.loc()` without explanation (needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySubdataset = rca_ds_chlor.loc[dict(time = slice(time0, time1))]\n",
    "mySubdataset.dims\n",
    "# mySubdataset gives the usual full Data variables list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = dt64('2019-06-23T00')            # a known good start time\n",
    "time1 = time0 + td64(24, 'h')            # 20 hours later; a good time range\n",
    "\n",
    "rca_subds_chlor = rca_ds_chlor.sel(time = slice(time0, time1))\n",
    "# print(rca_subds_chlor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_subds_chlor_depth = rca_subds_chlor.where(rca_subds_chlor.int_ctd_pressure <= 50., drop=True)\n",
    "rca_subds_chlor_depth2 = rca_subds_chlor_depth.where(rca_subds_chlor_depth.int_ctd_pressure > 40., drop=True)\n",
    "\n",
    "# one UTC day, 24 hours, 10 meter depth range 40 to 50 meters: 3094 values\n",
    "rca_reference = []\n",
    "\n",
    "rca_reference.append(rca_subds_chlor_depth2.fluorometric_chlorophyll_a.values.mean())\n",
    "rca_reference.append(rca_subds_chlor_depth2.fluorometric_chlorophyll_a.values.std())\n",
    "rca_reference.append(rca_subds_chlor_depth2.fluorometric_cdom.values.mean())\n",
    "rca_reference.append(rca_subds_chlor_depth2.fluorometric_cdom.values.std())\n",
    "rca_reference.append(rca_subds_chlor_depth2.total_volume_scattering_coefficient.values.mean())\n",
    "rca_reference.append(rca_subds_chlor_depth2.total_volume_scattering_coefficient.values.std())\n",
    "rca_reference.append(rca_subds_chlor_depth2.seawater_temperature.values.mean())\n",
    "rca_reference.append(rca_subds_chlor_depth2.seawater_temperature.values.std())\n",
    "rca_reference.append(rca_subds_chlor_depth2.practical_salinity.values.mean())\n",
    "rca_reference.append(rca_subds_chlor_depth2.practical_salinity.values.std())\n",
    "rca_reference.append(rca_subds_chlor_depth2.seawater_scattering_coefficient.values.mean())\n",
    "rca_reference.append(rca_subds_chlor_depth2.seawater_scattering_coefficient.values.std())\n",
    "rca_reference.append(rca_subds_chlor_depth2.optical_backscatter.values.mean())\n",
    "rca_reference.append(rca_subds_chlor_depth2.optical_backscatter.values.std())\n",
    "\n",
    "rca_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rca_subds_chlor.time[0], rca_subds_chlor.time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_check = []\n",
    "\n",
    "this_check.append(rca_subds_chlor_depth2.fluorometric_chlorophyll_a.values.mean())\n",
    "this_check.append(rca_subds_chlor_depth2.fluorometric_chlorophyll_a.values.std())\n",
    "this_check.append(rca_subds_chlor_depth2.fluorometric_cdom.values.mean())\n",
    "this_check.append(rca_subds_chlor_depth2.fluorometric_cdom.values.std())\n",
    "this_check.append(rca_subds_chlor_depth2.total_volume_scattering_coefficient.values.mean())\n",
    "this_check.append(rca_subds_chlor_depth2.total_volume_scattering_coefficient.values.std())\n",
    "this_check.append(rca_subds_chlor_depth2.seawater_temperature.values.mean())\n",
    "this_check.append(rca_subds_chlor_depth2.seawater_temperature.values.std())\n",
    "this_check.append(rca_subds_chlor_depth2.practical_salinity.values.mean())\n",
    "this_check.append(rca_subds_chlor_depth2.practical_salinity.values.std())\n",
    "this_check.append(rca_subds_chlor_depth2.seawater_scattering_coefficient.values.mean())\n",
    "this_check.append(rca_subds_chlor_depth2.seawater_scattering_coefficient.values.std())\n",
    "this_check.append(rca_subds_chlor_depth2.optical_backscatter.values.mean())\n",
    "this_check.append(rca_subds_chlor_depth2.optical_backscatter.values.std())\n",
    "\n",
    "\n",
    "test_result = [0.3604830856472429,\n",
    "               0.1919204481891048,\n",
    "               1.0962848650762613,\n",
    "               0.17839049820310146,\n",
    "               0.0008212006132186154,\n",
    "               0.00204944404433351,\n",
    "               10.024135745630813,\n",
    "               0.5840680323759343,\n",
    "               32.457901950062556,\n",
    "               0.0374061403722503,\n",
    "               0.0006297161117352217,\n",
    "               1.205469921244279e-06,\n",
    "               0.005532910531591812,\n",
    "               0.013855694492444818]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_subds_chlor_depth2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_subds_chlor_depth2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_subds_chlor_depth2.int_ctd_pressure.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_subds_chlor.int_ctd_pressure[:20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rca_subds_chlor_pressure = rca_subds_chlor.filter_by_attrs(\n",
    "# where(int_ctd_pressure < 100., drop=True)\n",
    "rca_subds_chlor_pressure = rca_subds_chlor.reset_coords(int_ctd_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_subds_chlor_pressure.int_ctd_pressure.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_ds_chlor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curtain plots of several profiler sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incomplete: Missing are the lower charts and an automated range calculation.\n",
    "\n",
    "From this point we use another boolean switch to skip over the subsequent charts (some of which take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Expect about 10 minutes for this to run: At full resolution (see to do list)\n",
    "\n",
    "# ['thermal',\n",
    "#  'haline',\n",
    "#  'solar',\n",
    "#  'ice',\n",
    "#  'gray',\n",
    "#  'oxy',\n",
    "#  'deep',\n",
    "#  'dense',\n",
    "#  'algae',\n",
    "#  'matter',\n",
    "#  'turbid',\n",
    "#  'speed',\n",
    "#  'amp',\n",
    "#  'tempo',\n",
    "#  'rain',\n",
    "#  'phase',\n",
    "#  'topo',\n",
    "#  'balance',\n",
    "#  'delta',\n",
    "#  'curl',\n",
    "#  'diff',\n",
    "#  'tarn']\n",
    "\n",
    "t0 = dt64('2019-07-10T00:00')                \n",
    "t1 = dt64('2019-07-11T00:00')\n",
    "\n",
    "#     pressure    = ds.int_ctd_pressure\n",
    "#     time_x_axis = ds.time\n",
    "#     chlor       = ds.fluorometric_chlorophyll_a\n",
    "#     cdom        = ds.fluorometric_cdom\n",
    "#     volscat     = ds.total_volume_scattering_coefficient\n",
    "#     temp        = ds.seawater_temperature\n",
    "#     salinity    = ds.practical_salinity\n",
    "#     seascat     = ds.seawater_scattering_coefficient\n",
    "#     optiback    = ds.optical_backscatter\n",
    "\n",
    "nPlots = 2\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "p,a=plt.subplots(nPlots, 1, figsize=(20,7*nPlots))\n",
    "\n",
    "# norm = mplcolors.Normalize(vmin=0.0,vmax=0.7)\n",
    "# removed norm = norm...\n",
    "aindex = 0\n",
    "a[aindex].scatter(time_x_axis.values, pressure, cmap=cmocean.cm.algae, c=chlor, marker= ',', s = 1.0)\n",
    "a[aindex].set(ylim=(200., 0.0), xlim = (t0, t1))\n",
    "\n",
    "\n",
    "#     plt.rcParams.update({'font.size': 14})\n",
    "#     a[aindex].set(title='Chlorophyll with time and depth')\n",
    "#     plt.rcParams.update({'font.size': 10})\n",
    "#     a[aindex].set_ylabel('Pressure (dbar)')\n",
    "#     a[aindex].set_xlabel('Date')\n",
    "\n",
    "#     aindex = 1\n",
    "#     norm = mplcolors.Normalize(vmin=7.0,vmax=14.)\n",
    "#     a[aindex].scatter(time_x_axis.values, pressure, cmap=cmocean.cm.oxy, c=temp, norm=norm, marker= ',', s = 1.0)\n",
    "#     a[aindex].set(ylim=(200., 0.0), xlim = (t0, t1))\n",
    "#     plt.rcParams.update({'font.size': 14})\n",
    "#     a[aindex].set(title='Temperature with time and depth')\n",
    "#     plt.rcParams.update({'font.size': 10})\n",
    "#     a[aindex].set_ylabel('Pressure (dbar)')\n",
    "#     a[aindex].set_xlabel('Date')\n",
    "\n",
    "#     aindex = 2\n",
    "#     norm = mplcolors.Normalize(vmin=7.0,vmax=14.)\n",
    "#     a[aindex].scatter(time_x_axis.values, pressure, cmap=cmocean.cm.oxy, c=optiback, norm=norm, marker= ',', s = 1.0)\n",
    "#     a[aindex].set(ylim=(200., 0.0), xlim = (t0, t1))\n",
    "#     plt.rcParams.update({'font.size': 14})\n",
    "#     a[aindex].set(title='Optical backscatter with time and depth')\n",
    "#     plt.rcParams.update({'font.size': 10})\n",
    "#     a[aindex].set_ylabel('Pressure (dbar)')\n",
    "#     a[aindex].set_xlabel('Date')\n",
    "\n",
    "#     aindex = 3\n",
    "#     norm = mplcolors.Normalize(vmin=7.0,vmax=14.)\n",
    "#     a[aindex].scatter(time_x_axis.values, pressure, cmap=cmocean.cm.oxy, c=salinity, norm=norm, marker= ',', s = 1.0)\n",
    "#     a[aindex].set(ylim=(200., 0.0), xlim = (t0, t1))\n",
    "#     plt.rcParams.update({'font.size': 14})\n",
    "#     a[aindex].set(title='Salinity with time and depth')\n",
    "#     plt.rcParams.update({'font.size': 10})\n",
    "#     a[aindex].set_ylabel('Pressure (dbar)')\n",
    "#     a[aindex].set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanded chlorophyll curtain plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treats the below-100-meters and above-100-meters as two separate colormap tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Re-do these from the resampled data\n",
    "\n",
    "from matplotlib import colors as mplcolors\n",
    "\n",
    "if doShallowProfilerChlorophyllCharts:\n",
    "\n",
    "    t0 = dt64('2019-06-01T00:00')                \n",
    "    t1 = dt64('2019-09-01T00:00')\n",
    "\n",
    "    pressure = ds.int_ctd_pressure\n",
    "    time_x_axis = ds.time\n",
    "    chlor = ds.fluorometric_chlorophyll_a\n",
    "\n",
    "\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    p,a=plt.subplots(2, 1, figsize=(14,14))\n",
    "\n",
    "    norm = mplcolors.Normalize(vmin=0.0,vmax=0.5)\n",
    "    a[0].scatter(time_x_axis.values, pressure, cmap='jet', c=chlor, norm=norm, marker= ',', s = 1.0)\n",
    "    a[0].set(ylim=(100., 0.0), xlim = (t0, t1))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    a[0].set(title='Chlorophyll with time and depth')\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    a[0].set_ylabel('Pressure (dbar)')\n",
    "    a[0].set_xlabel('Date')\n",
    "\n",
    "    norm = mplcolors.Normalize(vmin=0.0,vmax=0.1)\n",
    "    a[1].scatter(time_x_axis.values, pressure, cmap='jet', c=chlor, norm=norm, marker= ',', s = 1.0)\n",
    "    a[1].set(ylim=(200., 100.0), xlim = (t0, t1))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    a[1].set(title='Chlorophyll with time and depth')\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    a[1].set_ylabel('Pressure (dbar)')\n",
    "    a[1].set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double chlorophyll lens July 20 2019 (3 profiles) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask whether the recorded signal is a mirror image as the profiler rises and falls. To see this\n",
    "it helps to have a double-y-axis as shown in [this example](https://matplotlib.org/gallery/api/two_scales.html). \n",
    "\n",
    "\n",
    "Below we have three consecutive profiles over the course of seven hours which all demonstrate a double-maximum\n",
    "in chlorophyll concentration: One at about 30 meters and another at about 55 meters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Precision section works with precise times versus day-scale\n",
    "#   The precise times are an experiment in using 2 hours 40 minutes to chop up the 9 profiles in the day in a regular manner...\n",
    "#   but a better approach would be to detect the profiles and time-box each one individually. \n",
    "# \n",
    "\n",
    "t0 = dt64('2019-07-20T11:00')\n",
    "t1 = dt64('2019-07-20T18:00')\n",
    "dss = ds.sel(time=slice(t0, t1))\n",
    "len(dss.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,a=plt.subplots(2, 1, figsize=(14,14))\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "chlor_a = dss.fluorometric_chlorophyll_a\n",
    "chlor_a_min = chlor_a.rolling(time=60, center=True).min()\n",
    "pressure = dss.int_ctd_pressure\n",
    "\n",
    "a[0].plot(dss.time, chlor_a_min, color='g')\n",
    "a[1].scatter(pressure, chlor_a, color='k', marker= 'D', s = 4.0) \n",
    "\n",
    "a[0].set(ylim=(0., 0.55), xlim = (t0, t1), title='Shallow profiler: Chlorophyll (green) and pressure (blue) over seven hours')\n",
    "a[1].set(ylim=(0., 0.8), xlim = (0., 200.), title='Persistent double maximum: Chlorophyll with pressure')\n",
    "\n",
    "a[0].set_ylabel('Chlorophyll (ug L-1)')\n",
    "a[0].set_xlabel('Time: July 20 2019, hours 11 - 18')\n",
    "a[0].tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "a[1].set_ylabel('Chlorophyll (ug L-1)')\n",
    "a[1].set_xlabel('Pressure (dbar)')\n",
    "a[1].tick_params(axis='y', labelcolor='k')\n",
    "\n",
    "a0p = a[0].twinx()\n",
    "a0p.set_ylabel('Pressure (dbar)')\n",
    "a0p.plot(dss.time, pressure, color='blue')\n",
    "a0p.tick_params(axis='y', labelcolor='blue')\n",
    "a0p.set(ylim=(200., 0.), title='   ')\n",
    "\n",
    "# Optional formatting code: p.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animating chlorophyll depth profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From August 1 to August 15 2019 we have 9 profiles per day of the water column at the Oregon Slope Base site.  \n",
    "The objective here is to animate these 135 profiles: Depth on the y-axis and chlorophyll concentration on \n",
    "the x-axis. Each frame of the animation is a single profile featuring both rise and descent tracks. \n",
    "\n",
    "* [JS Animation in Jupyter notebooks 2nd blog post (update to original)](http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-as-interactive-javascript-widgets/)\n",
    "* `HTML(anim.to_html5_video())` generates the animation with minimal controls (including download)\n",
    "* `HTML(anim.to_jshtml())` generates the animation with several playback controls\n",
    "\n",
    "\n",
    "*ffmpeg* installation is necessary: `conda install -c conda-forge ffmpeg`\n",
    "\n",
    "\n",
    "##### In both cases I get a static view below the animated one, a bug\n",
    "\n",
    "##### Steps\n",
    "\n",
    "1. Define chart parameters\n",
    "2. Define initialization and animation functions\n",
    "3. Instantiate an animation object\n",
    "4. Generate the animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doShallowProfilerChlorophyllAnimation = False\n",
    "\n",
    "if doShallowProfilerChlorophyllAnimation:\n",
    "    # 1. Chart setup\n",
    "    fig, ax = plt.subplots(figsize=(7,14))     # creates a vertically elongated chart (7 is width)\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "    ax.set_xlim(( 0., 1.))\n",
    "    ax.set_ylim((125., 0.))\n",
    "    ax.tick_params(axis='y', labelcolor='k')\n",
    "    ax.set_ylabel('Pressure (dbar)', fontsize=16)\n",
    "    ax.set_xlabel('Chlorophyll (ug L-1)', fontsize=16)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    ax.set(title='Time series: \\n Chlorophyll (x) with Pressure (y)')\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "    # divides the day up into approximately 9 intervals of 2 hours 40 minutes\n",
    "    proftime = ['00:00', '02:40', '05:20', '08:00', '10:40', '13:20', '16:00', '18:40', '21:20', '23:59']\n",
    "\n",
    "    # Each render of the profile chart will try to blank out the prior datetime\n",
    "    prev_msg = '              '\n",
    "\n",
    "    # matplotlib plot object assigned to variable 'line' with some interesting syntax 'line,'\n",
    "    #   ax.plot() returns a tuple with just one element\n",
    "    #   using 'line,' syntax assigns the first (and only) element of this tuple to 'line'\n",
    "    #   There are other syntactical alternatives to this economical convention\n",
    "    #     Equivalent: [line] = ax.plot([], [], lw=3)\n",
    "    #     Equivalent: line = ax.plot([], [], lw=3)[0]\n",
    "    line, = ax.plot([], [], lw=3)\n",
    "\n",
    "\n",
    "# A scatter plot is a more involved proposition than is a basic .plot()\n",
    "# For example the following does not work:\n",
    "#   line, = ax.scatter([], [], color='k', marker='D', s = 4.0)\n",
    "\n",
    "\n",
    "# 2. Initialize and Animation functions\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "def animate(i):\n",
    "    global prev_msg\n",
    "    day = i//9 + 1\n",
    "    prof = i%9\n",
    "    if day < 10: day1 = '0' + str(day)\n",
    "    else: day1 = str(day)\n",
    "    day2 = day1\n",
    "    \n",
    "    # '2019-07-20T11:00'\n",
    "    t0string = '2019-08-' + day1 + 'T' + proftime[prof]\n",
    "    t1string = '2019-08-' + day2 + 'T' + proftime[prof+1]    \n",
    "    t0 = dt64(t0string)\n",
    "    t1 = dt64(t1string)\n",
    "    ds_1day = ds.sel(time=slice(t0, t1))\n",
    "\n",
    "    chlor_a = ds_1day.fluorometric_chlorophyll_a\n",
    "    chlor_a_min = chlor_a.rolling(time=60, center=True).min()\n",
    "    pressure = ds_1day.int_ctd_pressure\n",
    "    \n",
    "    # ax.scatter(pressure, chlor_a, color='k', marker= 'D', s = 4.0) \n",
    "\n",
    "    line.set_data(chlor_a_min, pressure)\n",
    "\n",
    "    # speculative line of code...\n",
    "    ax.text(0.5, 120., prev_msg, rotation=0, fontsize=18, color='white', fontweight='bold')\n",
    "    ax.text(0.5, 120., str(t0), rotation=0, fontsize=18, color='blue', fontweight='bold')\n",
    "    prev_msg = str(t0)\n",
    "\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "if doShallowProfilerChlorophyllAnimation:\n",
    "    # 3. Instantiate an animation object\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=15*9, interval=100, blit=True)\n",
    "\n",
    "    # 4. Generate the animated video result\n",
    "    # simple animation, basic controls\n",
    "    HTML(anim.to_html5_video())                      \n",
    "    # second version: various playback controls: \n",
    "    # HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<video width=\"50%\" controls>\n",
    "      <source src=\"./chlorophyll_animation.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional Cabled Array discrete datatsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section concerns data collected during VISIONS cruises. First we have some contextual remarks.\n",
    "Below this is a markdown translation of a README file.\n",
    "\n",
    "\n",
    "The cruise is designated AT4212 (AT indicating R/V Atlantis). We have a CSV data file consisting of 79 columns.\n",
    "A set of adjacent rows corresponds to a single cast; where each row is a Niskin bottle closure. \n",
    "At Oregon Slope Base we have 2 casts with respectively 17 and 16 Niskin bottles. \n",
    "These were run 250 meters from the location of the Slope Base Shallow Profiler. Times are given in \n",
    "UTC as \n",
    "\n",
    "\n",
    "* June 14 2019 for the group of 17: 2019-06-14T11:24:21.000Z \n",
    "* June 27 2019 for the group of 16: 2019-06-27T19:38:18.000Z \n",
    "\n",
    "\n",
    "CSV column listings as follows (where I number from zero); skipping items of less interest:\n",
    "\n",
    "| idx | contains     | notes     |\n",
    "| :---- | :--------------------: | -------------------------------------------: |\n",
    "|  0 | cruise   | always AT4212    |\n",
    "|  3 | latitude   | dd     |\n",
    "| 4 | longitude | dd    |\n",
    "| 4 | start time | UTC    |\n",
    "| 78 | some carbon flag | last entry  |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### README file: Cabled-10_AT4212_Discrete_Summary Information:\n",
    "\n",
    "\n",
    "##### File Mapping\n",
    "\n",
    "Hex files were renamed from the original ship-provided files for consistency and ease of processing.  \n",
    "Original file names are listed below on the left, with corresponding new file names on the right.  \n",
    "Original Hex files are accessible for each cruise in the Cruise Data folder under the “Ship Data” \n",
    "sub-directory.  Bottle files used to populate the discrete summary can be found in the Water Sampling \n",
    "sub-directory under “Shipboard Data”.\n",
    "\n",
    "\n",
    "```\n",
    "at4212001 = AT4212_CTD-001\n",
    "at4212002 = AT4212_CTD-002\n",
    "at4212003 = AT4212_CTD-003\n",
    "at4212004 = AT4212_CTD-004\n",
    "at4212005 = AT4212_CTD-005\n",
    "at4212006 = AT4212_CTD-006\n",
    "at4212007 = AT4212_CTD-007\n",
    "at4212008 = AT4212_CTD-008\n",
    "at4212009 = AT4212_CTD-009\n",
    "at4212010 = AT4212_CTD-010\n",
    "at4212011 = AT4212_CTD-011\n",
    "at4212012 = AT4212_CTD-012\n",
    "at4212013 = AT4212_CTD-013\n",
    "at4212014 = AT4212_CTD-014\n",
    "at4212015 = AT4212_CTD-015\n",
    "J2-1160_20190620_0400 = AT4212_J2-1160_20190619_0500\n",
    "J2-1161_20190620_0400 = AT4212_J2-1161_20190619_1300\n",
    "J2-1163_20190620_0400 = AT4212_J2-1163_20190620_0400\n",
    "```\n",
    "\n",
    "\n",
    "Summary Notes:\n",
    "\n",
    "\n",
    "```\n",
    "AT4212, CTD-001, Cast Flag: “no cast log, bottom depth is approximate”\n",
    "AT4212, CTD-002, Cast Flag: “no cast log, bottom depth is approximate”\n",
    "AT4212, CTD-003, Cast Flag: “no cast log, bottom depth is approximate”\n",
    "AT4212, CTD-004, Cast Flag: “no cast log, bottom depth is approximate”\n",
    "AT4212, CTD-005, Niskin 11, DIC flag: “too much headspace”\n",
    "AT4212, CTD-007, Niskin 20, Fluorescence Flag: “Filtering Assy leaked (<50 mL); can’t tell if pre- or post-filter”\n",
    "AT4212, CTD-008, Cast Flag: “Fire in Engine Room Cause premature cast end after Niskin 16”\n",
    "AT4212, CTD-008, Niskin 2, Salinity flag: “salt on bottleneck”\n",
    "AT4212, CTD-008, Niskin 13, Salinity flag: “salt on bottleneck”\n",
    "AT4212, CTD-010, Niskin 3, Salinity flag: “salt on bottleneck”\n",
    "AT4212, CTD-013, Niskin 5, Salinity flag: “salt on bottleneck”\n",
    "AT4212, CTD-015, Cast Flag: “Power loss, cast aborted, location and bottom depth approximate”\n",
    "```\n",
    "\n",
    "General File Notes:\n",
    "\n",
    "\n",
    "* Discrete sample fields containing text or non-decimal numbers (“DIC-###”, “CH-##”, “OX-###”, “SA####”, or “673”) \n",
    "list sample bottle numbers and not analyzed data. Bottle numbers are included when data are not yet available, \n",
    "and will be replaced with analysis results as data are received from analysis labs. \n",
    "* Fill value = -9999999\n",
    "* Carbon analysis was provided by Burke Hales lab at Oregon State University.  Calculated carbon parameters were \n",
    "provided by Hales using custom software routines using published values for the various carbon chemistry constants.  \n",
    "Hale’s lab provides the following references regarding constants used in the calculations.  For further information, \n",
    "please contact Burke Hales (bhales@coas.oregonstate.edu).\n",
    "* Carbonic acid dissociation constants: Millero (2010), with full resolution constants provided by Millero via private conversation, equal to Lueker’s constants at S > 25).\n",
    "* Kw: Millero (1995)\n",
    "* Kb: Dickson (1990)\n",
    "* Ksp for calcite and aragonite: Mucci (1980)\n",
    "* Kh: Weiss (1973)\n",
    "* Alkalnity is modeled as: HCO3- + 2CO3= + B(OH)4- + OH- - H+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to the discrete sample data. The objective is to\n",
    "compare two casts with coincident shallow profiler data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casts = pd.read_csv('ctdcasts_visions2019.csv')       # this will be a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(casts))\n",
    "print()\n",
    "print(type(casts.columns))    # An Index, i.e. an immutable ndarray implementing an ordered, sliceable set. \n",
    "                              #   Also: The basic object storing axis labels for all pandas objects.\n",
    "                              #   (indexing as a verb in pandas means data subsetting)\n",
    "print()\n",
    "print(casts.shape)            # gives 272 rows, 79 columns\n",
    "print()\n",
    "\n",
    "# This is a very entertaining thing to do (list methods/attributes): \n",
    "# g.dirnou(casts)\n",
    "\n",
    "# This lists the column headers starting with Cruise and Station\n",
    "for header in casts.columns[0:6]: print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(casts['Station'][17:36]) # 18 - 34 inclusive\n",
    "# print(casts['Station'][67:85]) # 68 - 83 inclusive\n",
    "print(type(casts['Station']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casts['Station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(casts['Station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in casts:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fails; fix \n",
    "# castSB2 = [a for a in casts if 'Slope' in a['Station']]\n",
    "# print(castSB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casts[[\"Station\"]] prints Station column values; shows '250m W of Slope Base Shallow Profiler'\n",
    "#   Create a subset DataFrame castSB for \"Slope Base\"\n",
    "castSB = casts[casts['Station'] == '250m W of Slope Base Shallow Profiler']\n",
    "print(castSB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other columns of interest from above\n",
    "#   Start time [UTC]\n",
    "#   Discrete Chlorophyll [ug/L]\n",
    "csbchl = castSB['Discrete Chlorophyll [ug/L]']\n",
    "print(type(csbchl))\n",
    "print(csbchl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "castSB['CTD Pressure [db]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "castSB['Start time [UTC]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata_chlor_a = csbchl[68]\n",
    "print(nodata_chlor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast_chlor_a2 = [a if a > 0. else np.nan for a in cast_chlor_a]\n",
    "# print(cast_chlor_a2)\n",
    "# print(cast_chlor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,a=plt.subplots(2, 1, figsize=(14,14))\n",
    "cast_chlor_a = castSB['Discrete Chlorophyll [ug/L]']\n",
    "cast_pressure = castSB['CTD Pressure [db]']\n",
    "\n",
    "cast_chlor_a.replace(nodata_chlor_a, 0.)\n",
    "print(cast_chlor_a[68])\n",
    "\n",
    "# a[0].plot(dss.time, chlor_a_min, color='g')\n",
    "# a[0].set(ylim=(0., 0.55), xlim = (t0, t1), title='Shallow profiler: Chlorophyll (green) and pressure (blue) over seven hours')\n",
    "# a[0].set_ylabel('Chlorophyll (ug L-1)')\n",
    "# a[0].set_xlabel('Time: July 20 2019, hours 11 - 18')\n",
    "# a[0].tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "a[0].plot([a if a > 0. else np.nan for a in cast_pressure], \n",
    "          [a if a > 0. else np.nan for a in cast_chlor_a], color='k') \n",
    "# a[0].scatter(x-coordinate values, y-coordinate values, color='k', marker= 'D', s = 4.0) \n",
    "a[0].set(ylim=(0., 1.0), xlim = (0., 200.), title='VISIONS 2019 Cast chlorophyll at Slope Base')\n",
    "a[0].set_ylabel('Chlorophyll (ug L-1)')\n",
    "a[0].set_xlabel('Pressure (dbar)')\n",
    "a[0].tick_params(axis='y', labelcolor='k')\n",
    "\n",
    "# a0p = a[0].twinx()\n",
    "# a0p.set_ylabel('Pressure (dbar)')\n",
    "# a0p.plot(dss.time, pressure, color='blue')\n",
    "# a0p.tick_params(axis='y', labelcolor='blue')\n",
    "# a0p.set(ylim=(200., 0.), title='   ')\n",
    "\n",
    "# Optional formatting code: p.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare MODIS to the Regional Cabled Array: Chlorophyll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIS satellite images of surface chlorophyll "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summer 2019, over the Regional Cabled Array off Oregon coast\n",
    "\n",
    "In sequence: June 18, July 20, August 21, 2019.\n",
    "\n",
    "<BR>\n",
    "<img src=\"./MODIS_chlorophyll_18JUN2019.png\" style=\"float: left;\" alt=\"drawing\" width=\"550\"/>\n",
    "<div style=\"clear: left\"><BR>\n",
    "\n",
    "<BR>\n",
    "<img src=\"./MODIS_chlorophyll_20JUL2019.png\" style=\"float: left;\" alt=\"drawing\" width=\"550\"/>\n",
    "<div style=\"clear: left\"><BR>\n",
    "\n",
    "<BR>\n",
    "<img src=\"./MODIS_chlorophyll_21AUG2019.png\" style=\"float: left;\" alt=\"drawing\" width=\"550\"/>\n",
    "<div style=\"clear: left\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This comparison supposes that the Regional Cabled Array (RCA) and the MODIS satellites ought to agree on\n",
    "estimated surface chlorophyll. So it would be a good thing to check. Before getting to that however\n",
    "the narrative will cover the `yodapy` package for pulling data for the RCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIS simple dataset \"by hand\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section builds an `xarray Dataset` by hand from a small set of data points.\n",
    "\n",
    "\n",
    "At this point having ordered data and placed it nearby we are done using `yodapy`.\n",
    "From here on we focus on `xarray`, `matplotlib` and other Python utilities. \n",
    "\n",
    "\n",
    "MODIS estimates of surface chlorophyll at the Oregon Slope Base site are provided\n",
    "by Sarah Barnes and Derya Gumustel. (link to their nbk here) There are a dozen or so valid\n",
    "observations in summer 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code constructs a MODIS observation DataArray from two lists: A date list and a data list.\n",
    "#   Additional code demonstrates working with this DataArray and subsequently an xarray Dataset.\n",
    "\n",
    "# MODIS dates of observation\n",
    "modis_dates = [dt64('2019-06-02T11:15:00.0'), \\\n",
    "               dt64('2019-06-10T11:55:01.0'), \\\n",
    "               dt64('2019-06-18T11:15:00.0'), \\\n",
    "               dt64('2019-06-26T11:55:01.0'), \\\n",
    "               dt64('2019-07-04T11:15:00.0'), \\\n",
    "               dt64('2019-07-12T11:55:01.0'), \\\n",
    "               dt64('2019-07-20T11:15:00.0'), \\\n",
    "               dt64('2019-07-28T11:55:01.0'), \\\n",
    "               dt64('2019-08-05T11:15:00.0'), \\\n",
    "               dt64('2019-08-13T11:55:01.0'), \\\n",
    "               dt64('2019-08-21T11:15:00.0'), \\\n",
    "               dt64('2019-08-29T11:55:01.0')]\n",
    "\n",
    "# MODIS corresponding surface chlorophyll estimates\n",
    "modis_chl = [0.3483194, 0.49131608, 0.48018616, np.nan, np.nan, 0.2037715, 0.26320615, 0.3066225, \\\n",
    "        0.35098818, 0.579521, 0.67963886, 0.58974856]\n",
    "\n",
    "# Translating these two lists into a MODIS DataArray\n",
    "modis_da_chlor = xr.DataArray(modis_chl, dims=('time'), coords={'time': modis_dates})\n",
    "modis_da_chlor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given this DataArray: Provide an example of retrieving the numerical data values.\n",
    "#   Noting that the .values attribute provides an array of floats\n",
    "print(modis_da_chlor.values)\n",
    "print()\n",
    "print(modis_da_chlor.values[0])\n",
    "print()\n",
    "print('The mean of the numerical values is ' + \"%5.3f\" % modis_da_chlor.values[~np.isnan(modis_da_chlor.values)].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deconstructing that last print statement above\n",
    "\n",
    "\n",
    "In the preceding code block the final `print()` is a bit dense so let's deconstruct it.\n",
    "\n",
    "\n",
    "- `\"%5.3f\" % x` is a format statement for printing a float value `x` with three decimal places. \n",
    "- `modis_da_chlor.values` is a `numpy ndarray` (not a list) of the chlorophyll estimates from MODIS. \n",
    "  - A `DataArray` is thematically just one type of data\n",
    "- `np.isnan(...ndarray...)` is also of type `numpy ndarray`, in this case boolean `True` or `False` values\n",
    "  - `True` means the corresponding DataArray element is a `nan`; no valid data present\n",
    "- `~np.isnan(...ndarray...)` applies logical NOT to the prior result so that 'True' means 'valid data'\n",
    "- `modis_da_chlor.values[~np.isnan(...)]` reduces `modis_da_chlor.values` to only valid data\n",
    "  - The boolean array is used as a mask\n",
    "- `modis_da_chlor.values[...].mean()` returns the mean of the reduced 'only valid data' result above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modis_da_chlor.dims)\n",
    "print(modis_da_chlor.coords)\n",
    "modis_da_chlor.plot()             # there is no ambiguity about what to plot as a DataArray has just one type of data\n",
    "\n",
    "modis_ds_chlor = xr.Dataset({'MODIS chlorophyll': modis_da_chlor})       # The DataArray is translated into a Dataset\n",
    "modis_ds_chlor.attrs['units']='µg L-1'                        # Adding units as a metadata attribute\n",
    "modis_ds_chlor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check this mostly-redundant section on yodapy search/order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ooi.search(region='cabled', site='axial base shallow profiler', node='shallow profiler', instrument='CTD')\n",
    "# ooi.instruments                    # an attribute\n",
    "# ooi.data_availability()\n",
    "\n",
    "# This cell does not run by default because it generates a data retrieve\n",
    "if False:\n",
    "    begin_date = '2018-01-01'\n",
    "    end_date = '2018-01-02'\n",
    "    ooi.request_data(begin_date=begin_date, end_date=end_date)\n",
    "\n",
    "# Once the data order is complete we need a way of placing the URL in the ooi object so we do not have\n",
    "#   to repeat the query. That goes into the yodapy README also. Are you tired of re-running this cell? \n",
    "#   Just run ooi.to_xarray() and it will do the polling for you. \n",
    "#\n",
    "# This is also 'Falsed out'\n",
    "if False: \n",
    "    ooi.check_status()\n",
    "\n",
    "# In the above cell ooi.check_status() can be re-run as a status check until the request is filled.\n",
    "# If instead we use the .to_xarray() method the polling loop on the data request is automated. This \n",
    "#   could take some time; but when it works the end result is a list of Xarray Datasets. Why is this \n",
    "#   a list? Because the requested time range may produce results that are segmented in time, i.e. \n",
    "#   several Datasets. By returning them in sequence as a list we hope to recover everything available\n",
    "#   in a time-contiguous fashion (subject to data dropouts if there are any).\n",
    "if False: \n",
    "    ds = ooi.to_xarray()\n",
    "    ds[0]\n",
    "\n",
    "# Saving (say the first in the list) Dataset to a NetCDF file via .to_netcdf() will not work because \n",
    "# OOI data are not CF-compliant in format\n",
    "# ds[0].to_netcdf('fubar.nc')\n",
    "\n",
    "# This will reach into the OOI system (not the CAVA system) and download and save NetCDF content\n",
    "if False:\n",
    "    filenamelist = ooi.download_netcdfs()\n",
    "    print(len(filenamelist))\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "if False: \n",
    "    ooids = xr.open_dataset(filenamelist[0])  \n",
    "    ooids\n",
    "\n",
    "# better: use open_mfdataset(filenamelist) to concatenate a segmented result\n",
    "# caveat: don't use against hetero instrument results as these will not stack properly in a Dataset\n",
    "\n",
    "# Start over: search specific to chlorophyll via fluorometers. Notice the instruments value is a search term\n",
    "# ooi.search(region='cabled', instrument='fluorometer')\n",
    "# ooi.instruments                    # an attribute\n",
    "# ooi.data_availability()\n",
    "\n",
    "# to reset the filters use ooi.clear() to avoid sub-filtering filtered results to arrive at nothing!\n",
    "\n",
    "# The following table lists possible instruments as *column headers*. This is subsequently \n",
    "#   transposed in the data availability graph: rows for each instrument's time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to miss key data cautionary tale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the foregoing we got 12 fluorometer hits. These do not include \"Oregon Offshore\" which is the distal node\n",
    "of the Endeavor array that sits on the RCA for power and data. This means that it is necessary to go back and\n",
    "re-do the query to pick up Oregon Offshore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr in AWS S3 Object Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section touches on zarr files: Chopped-up data files that together comprise a larger dataset.\n",
    "\n",
    "\n",
    "**Why zarr?** Answer: Faster access to subsets of the complete dataset. \n",
    "\n",
    "\n",
    "**How can you be sure it is faster??** Answer: We can't! But the assertion and zarr file *build* options \n",
    "derive from experience.\n",
    "\n",
    "\n",
    "We are interested in moving computation to the cloud (a remote network of computers and storage) where a collection \n",
    "of zarr files is embedded in advance. Since the data are there we have two desirable corollaries: First anybody\n",
    "(particularly fellow scientists) can use the same environment to access this single copy of the data; no copying\n",
    "of data is required. Second: Any access to the data will be reasonably fast. \n",
    "\n",
    "\n",
    "**Why does this matter?** Answer: It does *not* matter unless the data and/or the computation is large, in some sense. \n",
    "A *large* dataset or a *large* computation requires a corresponding *large* compute resource. This is expensive to\n",
    "build and maintain; so traditionally the access to insight is restricted to *wealthy* people. However\n",
    "if we contrive a shared system -- what we here call the *public cloud* -- suddenly anyone can be granted access.\n",
    "That is *anyone* can have access to insight. This is the basic principle of what is called *open science*.\n",
    "\n",
    "\n",
    "**What constitutes a *'large'* dataset?** Answer: By way of example let's consider the MODIS satellite program. \n",
    "The two MODIS imaging satellites have been operating since 2002 and together image the earth every two days at a resolution\n",
    "of one kilometer (or less) across 36 spectral bands. (This is an oversimplification for the purpose of approximation.) \n",
    "At one byte per (pixel and spectral channel) we have 60 Terabytes of data to date. This\n",
    "is a *modestly large* dataset: Too large to fit on a USB drive or in an email for example.  \n",
    "\n",
    "\n",
    "In this notebook, above this point, we took a very traditional approach: We copied a small subset of the \n",
    "data into this environment.  The purpose of this *zarr* section is to introduce the idea of a centralized \n",
    "computing environment that provides access to anyone interested in using it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires install zarr...\n",
    "import s3fs\n",
    "cavapath = 'io2data-test/data/RS01SBPS-SF01A-3A-FLORTD101-streamed-flort_d_data_record'\n",
    "FS = s3fs.S3FileSystem(anon=True)        # because not using an AWS cred\n",
    "s3ds = xr.open_zarr(store=s3fs.S3Map(cavapath, s3=FS), consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarrchlor=s3ds.sel(time=slice('2019-06-01', '2019-09-30'))\n",
    "zarrchlor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarrchlor.fluorometric_chlorophyll_a.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An idea for when these plots take a long time...\n",
    "# from dask.diagnostics import ProgressBar\n",
    "# with ProgressBar():\n",
    "#     zarrchlor.plot.scatter(x='time', y='int_ctd_pressure', hue='fluorometric_chlorophyll_a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place in context: Notes on Parquet, Dask, Athena, Hive, SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a low level parquet breaks data in column-wise storage, many small files. Notice this is column-format, not \n",
    "row format as we are accustomed to in CSV files. When you read this into dask... a pandas data frame reads the \n",
    "entire file... but dask works on lazy eval so dask access to a parquet data ensemble (many of these small chunked \n",
    "files) is very efficient as lazy eval. \n",
    "\n",
    "\n",
    "Dask reads this data into a dask data frame (which we can consider virtualized / lazy); and a dask data frame is \n",
    "analogous to a pandas data frame with that virtualization. \n",
    "\n",
    "\n",
    "Athena gives an analogous end-result; it is an AWS service running Apache Hive under the hood. \n",
    "You are charged for every query, beware. The access protocol is a SQL query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix of charts `matplotlib` example code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 3 x 3 matrix of CTD and related-sensor time series charts from a `data_gallery` IPython notebook. \n",
    "\n",
    "\n",
    "```\n",
    "rn = range(9); rsi = range(7)\n",
    "\n",
    "p,a=plt.subplots(3, 3, figsize=(14,14))\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "a[0,0].plot(ctdF.time, ctdF.depth, color='r');                                  a[0,0].set(ylim=(200.,0.), title='Depth')\n",
    "a[0,1].plot(ctdF.time, ctdF.salinity, color='k');                               a[0,1].set(title='Salinity')\n",
    "a[0,2].plot(ctdF.time, ctdF.temperature, color='b');                            a[0,2].set(title='Temperature')\n",
    "a[1,0].plot(ctdF.time, ctdF.dissolved_oxygen, color='b');                       a[1,0].set(title='Dissolved Oxygen')\n",
    "a[1,1].scatter(phF.time.values, phF.ph_seawater.values, color='r');             a[1,1].set(title='pH')\n",
    "a[1,2].scatter(nitrateF.time.values, nitrateF.scn.values, color='k');           a[1,2].set(title='Nitrate')\n",
    "a[2,0].plot(parF.time, parF.par_counts_output, color='k');                      a[2,0].set(title='Photosynthetic Light')\n",
    "a[2,1].plot(fluorF.time, fluorF.fluorometric_chlorophyll_a, color='b');         a[2,1].set(title='Chlorophyll')\n",
    "a[2,2].plot(siF.time, siF.si0, color='r');                                      a[2,2].set(title='Spectral Irradiance')\n",
    "\n",
    "a[2,0].text(dt64('2017-08-21T07:30'), 155., 'local midnight', rotation=90, fontsize=15, color='blue', fontweight='bold')\n",
    "a[2,2].text(dt64('2017-08-21T07:30'), 4.25, 'local midnight', rotation=90, fontsize=15, color='blue', fontweight='bold')\n",
    "\n",
    "tFmt   = mdates.DateFormatter(\"%H\")                 # an extended format for strftime() is \"%d/%m/%y %H:%M\"\n",
    "t0, t1 = ctdF.time[0].values, ctdF.time[-1].values  # establish same time range for each chart\n",
    "tticks = [dt64('2017-08-21T06:00'), dt64('2017-08-21T12:00'), dt64('2017-08-21T18:00')]\n",
    "\n",
    "for i in rn: j, k = i//3, i%3; a[j, k].set(xlim=(t0, t1),xticks=tticks); a[j, k].xaxis.set_major_formatter(tFmt)\n",
    "print('')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two `.sel()` time slice examples (different precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two ways of stipulating time slice arguments for a Dataset .sel()\n",
    "#   First uses a datetime64 and is precise to minutes (or finer)\n",
    "#   Second passes strings that are interpreted as days, inclusive\n",
    "#\n",
    "# if do_precision:  \n",
    "#    t0 = dt64('2019-06-01T00:00')\n",
    "#    t1 = dt64('2019-06-01T05:20')\n",
    "#    dss = ds.sel(time=slice(t0, t1))   \n",
    "# else:\n",
    "#     day1 = '24'\n",
    "#     day2 = '27'              # will be 'day 27 inclusive' giving four days of results\n",
    "#     dss = ds.sel(time=slice('2019-06-' + day1, '2019-08-' + day2))\n",
    "# len(dss.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The **heat blob** in the northeast Pacific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From\n",
    "\n",
    "https://www.fisheries.noaa.gov/feature-story/new-marine-heatwave-emerges-west-coast-resembles-blob\n",
    "\n",
    "<BR>\n",
    "<img src=\"./blob2014_2019.png\" style=\"float: left;\" alt=\"drawing\" width=\"750\"/>\n",
    "<div style=\"clear: left\"><BR>\n",
    "    \n",
    "    \n",
    "We would like to see this in our data and a characterization: This big by that wide by this deep, this many Joules..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Heidi Sosik's Imaging Flow Cytometer (WHOI)](http://ifcb-data.whoi.edu/mvco)\n",
    "  * [Same but API-specific](http://ifcb-data.whoi.edu/api)\n",
    "* [BCO-DMO (WHOI)](https://www.bco-dmo.org/data)\n",
    "* ARGO\n",
    "  * [GitHub pyARGO](https://github.com/castelao/pyARGO) Rob is not convinced this is complete enough to be useful...\n",
    "  * [UCSD ARGO Informational FAQ](http://www.argo.ucsd.edu/Data_FAQ.html#RorD)\n",
    "  * [Coriolis map-based data selection tool](http://www.argodatamgt.org/Access-to-data/Argo-data-selection)\n",
    "  * [xarray lesson that works with ARGO data](https://rabernat.github.io/research_computing/xarray.html)\n",
    "* GLODAP\n",
    "* AQUA\n",
    "* TERRA\n",
    "* OOI CA CI\n",
    "* ECCO2\n",
    "* LIVE OCEAN\n",
    "* NANOOS\n",
    "* [Braindr](https://braindr.us/#/), [Whaledr](https://whale-dr.firebaseapp.com/#/play), [appstract](https://appstract.pub/#/play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task list (ideas on improving this content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maps maps maps\n",
    "* Get more from `data_gallery_source.ipynb`\n",
    "* Set up binder including a data load\n",
    "* Curriculum versions\n",
    "  * Elementary level (see `synoptic/basics` photo tour!) \n",
    "  * Middle school level (Janel, Christina)\n",
    "  * High school level (educator?)\n",
    "  * College 100 level\n",
    "  * College upper level\n",
    "  * College capstone\n",
    "* Image management\n",
    "  * Image subdirectories will clean up the main directory: `imchlor`, `imgolive`, `imjourney`\n",
    "* ARGO\n",
    "    * Re-do the data get including result maps by year\n",
    "    * Sort out good coincidences\n",
    "        * Euclidean with 1 deg longitude = 111 km * cosine (latitude)\n",
    "* GLODAP\n",
    "    * 'nearest' CTD profiles at the RCA sites\n",
    "    * Also ARGO also MODIS\n",
    "* Test: Can .plot.scatter() be used to animate a scatter chart?\n",
    "* Test: Ascent versus Descent scatter chart in relation to y = x\n",
    "* Desirable: inspect the OOI() object to *see* its search state\n",
    "* Explode the mask on packages, modules and methods!\n",
    "  * Use `?ooi.search`\n",
    "  * Use `cmocean` for a case study\n",
    "  * `# Package exploration: Can follow the package name with a question mark: \"cmocean?\"`\n",
    "  * `# help(cmocean)                        # this reveals that `cm` is an available method   `      \n",
    "  * `# help(cmocean.cm)                     # this lists available color maps; see the GLODAP section below`\n",
    "\n",
    "\n",
    "* Explain the MODIS resolution situation\n",
    "  * `https://oceancolor.gsfc.nasa.gov/forum/oceancolor/topic_show.pl?tid=5570` from Sarah and Derya\n",
    "  * `https://modis.gsfc.nasa.gov/about/specifications.php`\n",
    "  * `https://earthdata.nasa.gov/collaborate/open-data-services-and-software/data-information-policy/data-levels`\n",
    "  * `http://www.ioccg.org/reports/report4.pdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide to panoply of earlier work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `synoptic / basics`\n",
    "  * `VISIONS_photo_tour.ipynb` is co-located with folders containing photos; simple photo browser using Markdown/HTML\n",
    "  * parent directory has a `README.md` file listing out the contents of an earlier version of Jupyter notebooks\n",
    "* `othermathclub / images` has a wealth in folders by subject\n",
    "* `notebooks / dev_notebooks / rob`: consolidation of old scraps of code (hydrophone, Shiv's ML101, NASA CMR, etcetera)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
