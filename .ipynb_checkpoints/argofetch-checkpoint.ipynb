{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARGO data fetch\n",
    "\n",
    "\n",
    "This notebook describes the process of ordering ARGO data (circa 2019). It is a reference. For ARGO \n",
    "data analysis in the context of the book please see the `argo.ipynb` notebook. \n",
    "\n",
    "\n",
    "## ARGO Drifters\n",
    "\n",
    "\n",
    "[ARGO drifters](https://argo.ucsd.edu/faq/#look) are carefully designed scientific instruments.\n",
    "Physically they are cylinders about 20 cm in diameter and 1.3 m in length. They use a buoyancy control \n",
    "bladder to regulate their depth and they measure temperature, salinity, pressure and additional\n",
    "biogeochemical observables within the ocean. ARGO drifters typically float in the deep ocean\n",
    "at a depth of 1000 meters. After residing at that depth for ten days they descend to 2000 m and \n",
    "then ascend through the water column to the surface where they report back via satellite link. \n",
    "Then they return to 1000 meters and the process repeats for the life of the drifter, typically \n",
    "about four years. ARGO drifters are subject to ocean currents: They go where the ocean takes them. \n",
    "\n",
    "\n",
    "Our goal here is to review the process of obtaining ARGO data as 'scientist data customers'. \n",
    "\n",
    "\n",
    "## Obtain ARGO data\n",
    "\n",
    "ARGO drifters are distributed throughout the global ocean. Each periodically telemeters recent data \n",
    "(say 10 days worth) back to a data system. This section briefly reviews searching for and obtaining\n",
    "data from this system. As with the OOI system it is very much an \"order your data / wait for confirmation / \n",
    "download your order using ftp\" paradigm.\n",
    "\n",
    "### Search using correct date format dd-mm-yyyy\n",
    "\n",
    "* Coincident with the work in this notebook: 1-JUN-2019 to 1-SEP-2019\n",
    "  * ftp://ftp.ifremer.fr/ifremer/coriolis/tmp/co0501/DataSelection_20200129_183035_9538028.tgz\n",
    "* Full RCA time extent from Aug 1 2014\n",
    "  * 1-AUG-2014 to 1-JAN-2016\n",
    "  * ftp://ftp.ifremer.fr/ifremer/coriolis/tmp/co0501/DataSelection_20200129_190230_9538576.tgz\n",
    "  * 1-JAN-2016 to 1-JAN-2018\n",
    "  * ftp://ftp.ifremer.fr/ifremer/coriolis/tmp/co0501/DataSelection_20200129_190438_9538617.tgz\n",
    "  * 1-JAN-2018 to 28-JAN-2020\n",
    "  * ftp://ftp.ifremer.fr/ifremer/coriolis/tmp/co0501/DataSelection_20200129_190718_9538702.tgz\n",
    "  \n",
    "\n",
    "## ARGO resources\n",
    "\n",
    "- [GitHub pyARGO](https://github.com/castelao/pyARGO) is a Python library for ARGO; status uncertain\n",
    "- [UCSD ARGO Informational FAQ](http://www.argo.ucsd.edu/Data_FAQ.html#RorD)\n",
    "- [Coriolis map-based data selection tool](http://www.argodatamgt.org/Access-to-data/Argo-data-selection)\n",
    "- [xarray lesson that works with ARGO data](https://rabernat.github.io/research_computing/xarray.html)\n",
    "\n",
    "## Coriolis map interface\n",
    "\n",
    "Here is the map interface from **Coriolis** including the yellow bounding box and some green dot ARGO profiles.\n",
    "\n",
    "\n",
    "<BR>\n",
    "<img src=\"./images/argo/argomap1.png\" style=\"float: left;\" alt=\"drawing\" width=\"750\"/>\n",
    "<div style=\"clear: left\"><BR>\n",
    "    \n",
    "Here is the \"results\" feedback when the order completes.\n",
    "    \n",
    "<BR>\n",
    "<img src=\"./images/argo/argomap2.png\" style=\"float: left;\" alt=\"drawing\" width=\"750\"/>\n",
    "<div style=\"clear: left\"><BR>\n",
    "\n",
    "Coriolis finishes the data preparation in a matter of a minute or so. They tell you in advance the URL of \n",
    "your results, for example: \n",
    "\n",
    "```\n",
    "We are processing your data request.\n",
    "The data will be delivered: ftp://ftp.ifremer.fr/ifremer/coriolis/tmp/co0501/DataSelection_20180206_225551_5097076.tgz\n",
    "```\n",
    "\n",
    "## Order and retrieve an ARGO dataset at Coriolis \n",
    "\n",
    "- Use the map interface to navigate to a region of interst\n",
    "- Set (as above, yellow rectangle) a bounding box \n",
    "- Use the time controls to set a time range (I used Jun 1 -- Sep 1 2019)\n",
    "- Click on Refresh (in the control at the left of the map), wait for the Query to complete\n",
    "- Click Download to open the Data Selection tab in your browser. \n",
    "  - This click seems a bit inconsistent... might need a second try\n",
    "- Enter your email, click 'Extract your data': Produces the future URL of your dataset\n",
    "- You will receive a 'processing' confirmation email\n",
    "- You will receive an email with a link to the dataset when it is in place\n",
    "\n",
    "The URL has this format:\n",
    "\n",
    "```\n",
    "ftp://ftp.ifremer.fr/ifremer/coriolis/tmp/co0501/DataSelection_yyyymmdd_hhmmss_xxxxxx.tgz\n",
    "```\n",
    "\n",
    "This file expires and vanishes in an hour or two. So grab that data before it evaporates; \n",
    "and then put it somewhere stable.\n",
    "\n",
    "## Python ftp data pull from Coriolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jupyter Notebook running Python 3\n",
      "the data directory is /data/ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mini-source control\n",
    "# copied 29-SEP-202: to tilt* and chlorophyll*\n",
    "\n",
    "pangeo_jupyter = False\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob           # list files in a directory\n",
    "\n",
    "home_dir = os.getenv(\"HOME\")\n",
    "this_dir = home_dir + '/chlorophyll/'\n",
    "\n",
    "if pangeo_jupyter: data_dir = home_dir + '/data/'\n",
    "else: data_dir = '/data/'\n",
    "\n",
    "print('\\nJupyter Notebook running Python {}'.format(sys.version_info[0]))\n",
    "print('the data directory is', data_dir, '\\n')\n",
    "\n",
    "# Some notes on writing movies (ongoing project)\n",
    "#     This may be necessary on Pangeo: conda install -c conda-forge ffmpeg -y -q       \n",
    "#       ... noting that -y skips dialogs; -q reduces stdout clutter\n",
    "#     Note: On Pangeo `which ffmpeg` returns `/srv/conda/envs/notebook/bin/ffmpeg`\n",
    "#       ... plt.rcParams['animation.ffmpeg_path'] = '/srv/conda/envs/notebook/bin/ffmpeg' \n",
    "#       ... (matplotlib must see the movie writer 'ffmpeg')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mplcolors   # map data values to colors\n",
    "\n",
    "import warnings\n",
    "# turn off warnings using: warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from numpy import datetime64 as dt64, timedelta64 as td64\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# doy = day of year, indexed from 1 (1-JAN)\n",
    "# Day of year calculated directly from a datetime64\n",
    "def doy(theDatetime): return 1 + int((theDatetime - dt64(str(theDatetime)[0:4] + '-01-01')) / td64(1, 'D'))\n",
    "def dt64_from_doy(year, doy): return dt64(str(year) + '-01-01') + td64(doy-1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code (suitably modified) would pull data from Coriolis via ftp via in turn Python\n",
    "\n",
    "\n",
    "\n",
    "if False:           # Let's not run this fetch unless the data order is re-done and the parameters below are updated!\n",
    "    \n",
    "    \n",
    "    # My bounding box is the region of the Regional Cabled Array. Time = June 1 - Sep 1 2019.\n",
    "    from ftplib import FTP\n",
    "    dataIDString = '20200129_190718_9538702'\n",
    "    myIDString = './ARGO_Jan1_2018_Jan28_2020_Part3of3.tgz'         # This is arbitrary, to remember what I ordered\n",
    "    ftp = FTP('ftp.ifremer.fr')\n",
    "    ftp.login()\n",
    "    ftp.cwd('ifremer/coriolis/tmp/co0501/')\n",
    "    ftp.retrlines('LIST DataSelection_' + dataIDString + '.tgz')\n",
    "    ftp.retrbinary('RETR DataSelection_' + dataIDString + '.tgz', open(myIDString, 'wb').write)\n",
    "    ftp.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack ARGO data\n",
    "\n",
    "Suppose the data file is (for simplicity) **x.tgz**. I then run\n",
    "\n",
    "```\n",
    "$ gunzip x.tgz\n",
    "$ tar -xvf x.tar\n",
    "$ cd <un-tar directory>\n",
    "$ ...etcetera...\n",
    "```\n",
    "\n",
    "This gets the profile and transect files -- one for each drifter in the bounding box -- into my system as\n",
    "NetCDF files. In my case these are written to `~/data/argo` as `argo_profiles1.nc` and `argo_trajectory1.nc`. \n",
    "\n",
    "\n",
    "To formalize this with code here are some tools. These would be useful for a large campaign of ARGO analysis.\n",
    "\n",
    "\n",
    "```\n",
    "import os\n",
    "\n",
    "def ls(qual): return os.popen('ls -al ' + qual).readlines()\n",
    "    \n",
    "datasetList = []\n",
    "r = ls('*.tgz')\n",
    "for a in r: \n",
    "    c = a.split(' ')[8].split('.')[0]\n",
    "    if c not in datasetList: datasetList.append(c)\n",
    "        \n",
    "print(str(datasetList))\n",
    "\n",
    "for c in datasetList:\n",
    "    retvalue = os.popen('gunzip ' + c + '.tgz').readlines()\n",
    "    retvalue = os.popen('tar -xvf ' + c + '.tar').readlines()\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
