{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Dask and XArray Journey\n",
    "\n",
    "I thought it might be of value (after some encouragement) to write down impressions on learning dask and xarray; \n",
    "essential elements together with Intake-STAC of the Pangeo stack.\n",
    "\n",
    "\n",
    "## Preamble \n",
    "\n",
    "\n",
    "First I logged in to my Pangeo Jupyter Lab environment and grabbed the dask tutorial\n",
    "\n",
    "\n",
    "```\n",
    "clone https://github.com/dask/dask-tutorial\n",
    "```\n",
    "\n",
    "\n",
    "Then I watched about an hour of the YouTube workshop video from 2018. This unfortunately includes questions \n",
    "that are inaudible so the responses do not close the idea presented. Also there is very little motivation\n",
    "in the exposition so it is not clear \"why are we here?\" This is not to disparage the presentation which \n",
    "made tons of sense at the time in its context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XArray spadework\n",
    "\n",
    "So I have two *actual research* objectives. The first is to chart out all of the surging glaciers captured\n",
    "by remote sensing means since 1991. On earth. The second is to characterize the statistical behavior of\n",
    "the ocean water column at three locations in the Pacific for further use in oceanographicc biogeochemistry. \n",
    "I will refer to these respectively as the **Ice Problem** and the **Ocean Problem**. \n",
    "\n",
    "\n",
    "Earlier efforts on the Ice Problem taught me a few things about how XArray works. Let me explain that and \n",
    "also what I *suspect* will be the end-result of this program I'm on. \n",
    "\n",
    "\n",
    "### How XArray works\n",
    "\n",
    "First we need a data model; a collection of ideas and terms that abstractly describe \n",
    "many datasets, capturing their commonality. Here are some  \n",
    "[examples of Xarray in action](http://xarray.pydata.org/en/stable/examples.html)\n",
    "that help build context. Here are some key starting points from my experience:\n",
    "\n",
    "\n",
    "- XArray is built on two data container forms or *types*: The `Dataset` and the `DataArray`.\n",
    "  - I abbreviate these `ds` and `da`\n",
    "    - Also useful: Start a container name with a source, as in `glodap_`\n",
    "    - Also useful: Append sensor, as in `glodap_ds_temp` \n",
    "  - Create a Dataset out of thin air... or from a DataArray\n",
    "  - Create a DataArray out of thin air... or from a Dataset \n",
    "  - The Xarray formalism expands from `pandas` dataframes\n",
    "    - Consequently one should learn dataframes *first*\n",
    "      - By carefully following Jake VanDerplas' chapter on pandas\n",
    "  - An XArray `Dataset` is comprised of four sets with standard names\n",
    "    - These four components are interrelated\n",
    "    - A precise understanding of all four is extremely helpful\n",
    "    \n",
    "The parts of an Xarray Dataset:\n",
    "\n",
    "1. `dims`\n",
    "2. `something`\n",
    "3. `data variables` maybe?\n",
    "4. `attrs` is a dictionary of data attributes; metadata; descriptors. These can be created/deleted. \n",
    "    \n",
    "\n",
    "### Why do this? \n",
    "\n",
    "\n",
    "It is easy enough to do a very very focused investigation\n",
    "into a *small* collection of data of say *two* parameters at a *precise* location on the earth \n",
    "for a *narrow* range of time. You might analyze and publish an excellent paper on Pacific Chorus Frog \n",
    "chirps as observed in spring of 2007 at Lake Tapps, Washington. But you could well find yourself\n",
    "staying up into the small hours writing specialized code that cleans your data and renders\n",
    "the analysis and the key illustrative charts... then three months later\n",
    "find yourself doing the exact same painstaking preparation for a slightly different dataset \n",
    "beset with its own idiosyncracies. You think 'I wish I could write this code just once and for all and use \n",
    "it for all these special cases.' \n",
    "\n",
    "\n",
    "That's why we're here. The key is abstraction. Abstraction of data, of code, of compute\n",
    "infrastructure: All the components of data science where we really do not have the time\n",
    "for bespoke effort endlessly repeated. Our bet is that by going through this learning \n",
    "process we will find a net gain in time and effort in data analysis. \n",
    "\n",
    "\n",
    "Returning for a moment to one of our two practical examples: The Ice Problem was \n",
    "developed in a few-degrees-square region of Southeast Alaska (a single UTM zone)\n",
    "with a lot of moving ice. The method however applies to the Himalayas, to the \n",
    "Patagonian Icefield, to British Columbia and to many other glacier-covered regions. \n",
    "The Ice Problem computation could and should be run on a global scale over the \n",
    "full time extent of the available data, in excess of a decade, off of a single \n",
    "keystroke.\n",
    "\n",
    "\n",
    "### How XArray works in more detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dask narrative\n",
    "\n",
    "\n",
    "The first thing they try to teach us about Dask is that it has a method -- really a *decorator* -- that operates on a computational task\n",
    "in two phases. The first phase is where dask draws a graph of the problem; and the second phase is where dask grabs execution threads \n",
    "made available by the host computer and uses each of them to resolve the nodes of this graph which are of course smaller compute tasks\n",
    "that must be run in some implicit order. This implies there must be something very clever about dask that allows it to construct this\n",
    "directed acyclic *task solver* graph... but I suspect that the cleverness resides with us as coders. \n",
    "\n",
    "\n",
    "### Dask `delayed`\n",
    "\n",
    "\n",
    "We begin by using functions that have built in one-second delays that simulate some computing time. The do trivial things. \n",
    "The functions are themselves not touched by the dask formalism; but the composition of these functions into a compute task\n",
    "brings in the dask function `delayed`.\n",
    "\n",
    "\n",
    "I learn that `dask.delayed` is a Python *decorator* so here is what that means:\n",
    "\n",
    "\n",
    "> A decorator is a design pattern in Python that allows a user to add new functionality to an \n",
    "existing object without modifying its structure. Decorators are usually called before the \n",
    "definition of a function you want to decorate. [...] **Functions in Python [...] support operations \n",
    "such as being passed as an argument, returned from a function, modified, and assigned \n",
    "to a variable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need graphviz to see the graphs...\n",
    "\n",
    "```\n",
    "conda install graphviz\n",
    "```\n",
    "\n",
    "\n",
    "and then as it still seemed to be non-working...\n",
    "\n",
    "\n",
    "```\n",
    "pip install graphviz\n",
    "```\n",
    "\n",
    "It *seemed* like both were necessary but that seems odd... maybe just the `conda install` is all that was needed. Anyway now I have graphs that illustrate dask's thinking. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impressions of `dask.delayed`\n",
    "\n",
    "To understand the second and third examples I'm matching `delayed` mentally to any compute-heavy task.\n",
    "Here that means anything with a built-in `sleep(1)` to mimic a lot of work. So write out sequential code\n",
    "and stick `delayed(xxx)` around any slow `xxx()`. That's the recipe but it misses the implicit finesse \n",
    "from the narrative. I think this is 'the graph builds *instantaneously* and then executes *later* (\"when needed\")\n",
    "via parallel resources'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
