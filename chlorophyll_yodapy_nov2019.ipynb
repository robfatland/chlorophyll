{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on work in progress\n",
    "\n",
    "New here? This is a working oceanography notebook that includes learning notes. \n",
    "You might want to skip down to **Introduction**. \n",
    "\n",
    "\n",
    "### Further work\n",
    "\n",
    "* Make this 'run all cells' safe\n",
    "* Formalize the zarr notes at the end; and why zarr?\n",
    "* Ascent versus Descent scatter chart in relation to y = x\n",
    "* Mean / variance of chlorophyll with depth over time (also by time of day)\n",
    "* Incorporate cmocean colormaps\n",
    "* Comparative across three locations (OSB, OO, AB)\n",
    "* Comparative with VISIONS casts\n",
    "* Comparative with ARGO\n",
    "* Superimpose MODIS views on maps\n",
    "\n",
    "\n",
    "### Lat / Lon by Site\n",
    "\n",
    "```\n",
    "Site                    Lat               Lon\n",
    "------------------      ---               ---\n",
    "Oregon Offshore        44.37415        -124.95648\n",
    "Oregon Slope Base      44.52897        -125.38966 \n",
    "Axial Base             45.83049        -129.75326\n",
    "```   \n",
    "\n",
    "### On MODIS \n",
    "\n",
    "\n",
    "- We have Oregon Slope Base MODIS surface chlorophyll for three months in summer 2019\n",
    "  - June-September time frame, ~13 observations separated by 8 day intervals\n",
    "  - Other locations? Time ranges? \n",
    "- MODIS pixels are < 0.5 degrees latitude (56km). \n",
    "  - Double check; and this seems low in comparison with MODIS-native (500m Rob thinks)\n",
    "  - Pixel blocks of interest? Eddy structure visible? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "This notebook compares profiler chlorophyll measurements to surface chlorophyll observations by the \n",
    "MODIS satellite. The profiler operates in the upper 200 meters of the ocean off the coast of Oregon. \n",
    "It is maintained by the Regional Cabled Array program as part of the Ocean Observing Initiative.\n",
    "The first part of this notebook concerns getting profiler data using a Python package called **yodapy**;\n",
    "so let's start there and let the other facets of this work come into focus as we proceed. \n",
    "\n",
    "\n",
    "`yodapy` is a contraction of **Y**our **O**cean **DA**ta **PY**thon library. It was written \n",
    "by Don Setiawan to facilitate working with **OOI** data. Before `yodapy` was written we were \n",
    "obliged to manually follow a sequence of mysterious steps to get data of interest from OOI. \n",
    "Now by using the `yodapy` Python library we can search for, identify, order and download data \n",
    "*from within a block of code*, voila this notebook. \n",
    "\n",
    "\n",
    "This notebook reviews `yodapy` specific to the Regional Cabled Array (RCA) and as noted\n",
    "measurements of chlorophyll in the upper water column (the photic zone). However the methods\n",
    "and skills presented here are relevant to othe types of data and \n",
    "to other OOI segments. \n",
    "\n",
    "\n",
    "One other point before we begin: The OOI system requires you to *authenticate* as a sort of \n",
    "customer so you'll need to go register at their website. There is no cost and it only takes \n",
    "a couple of minutes. \n",
    "\n",
    "\n",
    "## Notebook features\n",
    "\n",
    "- Walk-through: Locating, ordering, and downloading data from OOI: Uses `yodapy`\n",
    "  - focus on the Regional Cabled Array (RCA)\n",
    "  - data are in NetCDF format, a good match to `xarray` \n",
    "- demonstrate working with `xarray` `DataArrays` and `Datasets` \n",
    "- demonstrate plotting with `matplotlib`\n",
    "  - line and scatter plots, multiple y-axes, labels, marker type and size\n",
    "  - profiler curtain plots: time - depth - chlorophyll (as color) \n",
    "  - animation\n",
    "\n",
    "***Run the following Python cells: Perfunctory configuration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the latest build of yodapy is installed directly from github using\n",
    "!pip install git+https://github.com/cormorack/yodapy.git -q     # -q cuts the stdout clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge ffmpeg -y -q                                       # -y skips dialogs; -q reduces stdout clutter\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/srv/conda/envs/notebook/bin/ffmpeg'    # matplotlib must see the movie writer 'ffmpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mplcolors   # map data values to colors\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "import numpy as np\n",
    "from numpy import datetime64 as dt64, timedelta64 as td64\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "# Local application/library specific imports\n",
    "from golive_library import GoliveLibrary as g\n",
    "\n",
    "# to learn yodapy set this to True\n",
    "learn_yodapy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip ahead?\n",
    "\n",
    "If you are returning to this notebook to continue prior work you have two skip ahead options at this point:\n",
    "\n",
    "* Skip to **(Skip-to-here point) Create a `yodapy` OOI instance** to continue working the data browse/order process\n",
    "* Skip to **(Skip-to-here point) MODIS Intermezzo** if your data is already in place in this Jupyter environment\n",
    "\n",
    "\n",
    "First time through? Run the next cell...\n",
    "\n",
    "- ... to verify that `yodapy` installed properly above\n",
    "- ... to get ready to configure your OOI credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learn_yodapy: from yodapy.utils.creds import set_credentials_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring `yodapy`\n",
    "\n",
    "\n",
    "### OOI data access back-story\n",
    "\n",
    "\n",
    "To order data from **OOI** requires you to pre-register (free, uses your email address). This provides you \n",
    "credentials when placing a data order. Orders typically take a few minutes for the OOI\n",
    "servers to assemble; after which you receive an email with a download link. You download the data to local storage\n",
    "and read files into memory and proceed from there, a very labor-intensive process.\n",
    "\n",
    "\n",
    "### How `yodapy` helps\n",
    "\n",
    "\n",
    "[`yodapy`](http://github.com/cormorack/yodapy) helps you automate OOI data access at each step. \n",
    "It sets up a credentials directory within your home directory;\n",
    "and in so doing helps you avoid accidentally pushing your credentials to `github` where they would be public. `yodapy` \n",
    "allows you to create a Python object called an `OOI()` that includes methods for finding sensor data of interest; \n",
    "for ordering time-bounded datasets for those sensors; for downloading this data; and for attaching it to a data \n",
    "structure (an `xarray Dataset`) for further analysis. It is at this point when you have your data present as a \n",
    "`Dataset` that `yodapy` has completed its job. \n",
    "\n",
    "\n",
    "The next cell installs `yodapy`. Run this each time you start up this notebook server unless your installation\n",
    "of the `yodapy` library persists. \n",
    "\n",
    "\n",
    "### Getting OOI credentials\n",
    "\n",
    "\n",
    "To get data from OOI you first create a User account as follows:\n",
    "\n",
    "\n",
    "- Visit the [OOI website](https://ooinet.oceanobservatories.org/#)\n",
    "- On the login menu (upper right) select **Register**\n",
    "- Fill out the New User Registration Form\n",
    "- Once you have your login credentials: Log in\n",
    "- The 'Login' menu should be replaced with your User name at the upper right: Also a dropdown menu\n",
    "  - Use this menu to select User Profile\n",
    "- At the bottom of your User Profile page you should find **API Username** and **API Token**\n",
    "  - These two strings comprise your authentication \n",
    "  - Keep them somewhere safe\n",
    "  - Notice that the **Refresh API Token** button permits you to regenerate them whenever you like\n",
    "\n",
    "\n",
    "Use your OOI API Token with `yodapy` as described further down to automate your authentication process.\n",
    "If this works as intended you can safely use OOI and not have to worry about cutting and pasting these\n",
    "token strings every time you want to get data access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your *local* OOI credentials using `yodapy`\n",
    "\n",
    "\n",
    "Only the first time through here: Carefully follow the instructions in the Python cell below.\n",
    "You are (temporarily) telling `yodapy` what your `OOI username` and `token` are. \n",
    "`yodapy` creates a hard-to-notice sub-directory of your home directory\n",
    "that contains these credentials in a text file. As long as you are not publishing\n",
    "your home directory someplace public your credentials will be hidden away.\n",
    "\n",
    "\n",
    "#### 'Why am I doing this?'\n",
    "\n",
    "\n",
    "When you use `yodapy` to order data from OOI it will use this 'hidden away' copy\n",
    "of your credentials to convince OOI your order is legitimate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the next line of code to create authentication credentials for the OOI data system. Do this\n",
    "# by ***carefully**** substituting your actual credentials in the username and token strings\n",
    "# in this line of code:\n",
    "\n",
    "\n",
    "# set_credentials_file(data_source='ooi', username='OOIAPI-XXXXXXXXXXXXXX', token='XXXXXXXXXXXX')\n",
    "\n",
    "\n",
    "# Un-comment the code and run the cell, just the one line above.\n",
    "# Once it runs: Comment it out again and delete your credentials. You can obscure them with XXXXX as they are seen now.\n",
    "# After you obscure your credentials: Be sure not to run this code again as it will break your authentication info.\n",
    "#\n",
    "# You can verify this worked by examining the .credentials file in ~/.yodapy. The credentials should match. Notice that \n",
    "#   this (slightly hidden) directory is directly connected to your home directory; whereas this IPython notebook \n",
    "#   is presumably in a distinct directory; so there should be no chance of a GitHub push sending your \n",
    "#   credentials to GitHub. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (skip-to-here point) Create a `yodapy` OOI instance\n",
    "\n",
    "The ooi instance will enable you to connect to data resources and get datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learn_yodapy: \n",
    "    from yodapy.datasources import OOI\n",
    "    ooi = OOI()\n",
    "    g.dirnou(ooi)\n",
    "\n",
    "# Run this to see all the components or segments of OOI available\n",
    "# ooi.sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can explore these methods and attributes further. Note that yodapy has a series of \n",
    "# attributes that begin with 'cava_'. 'cava' is shorthand for \"cabled array value add\", \n",
    "#   a project at the University of Washington School of Oceanography supporting cabled array\n",
    "#   data validation and use in ocean research.\n",
    "# help(ooi.cava_sites)\n",
    "if learn_yodapy: print(ooi.cava_sites, '\\n\\n\\n', ooi.cava_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ooi.search()` first example\n",
    "\n",
    "\n",
    "We will begin using `yodapy` proper to narrow down a data search. \n",
    "\n",
    "\n",
    "### What resources are available?\n",
    "\n",
    "\n",
    "Specifically what are the names of sites served by the Regional Cabled Array? \n",
    "We begin with a broad search giving only the keyword `region`. \n",
    "Then we narrow the search by adding including keywords `site`, `node`, and `instrument` \n",
    "to arrive at individual *instruments* or *sensors*. These search results are used to order \n",
    "datasets with a specified time range. \n",
    "\n",
    "\n",
    "This first example is the broad search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learn_yodapy: \n",
    "    # ooi.search(region='endurance')\n",
    "    ooi.search(region='cabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learn_yodapy: \n",
    "    # Attribute 'sites' gives broad results as a table of arrays, sites, descriptions, lat/lon: Across all of OOI (62 rows)\n",
    "    ooi.sites        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learn_yodapy: \n",
    "    # Narrow result: Within the Cabled Array region only (116 rows, 6 named columns)\n",
    "    ooi.instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The notion of a refined OOI search in `yodapy`\n",
    "\n",
    "\n",
    "The `OOI()` object provided by `yodapy` starts out in a very *broad view* state. It \"knows about\" the entire OOI: \n",
    "Endurance, Pioneer, Argentine Basin, the Cabled Array, Irminger Sea, Station Papa and so on. \n",
    "\n",
    "\n",
    "When we use the `.search()` method with keywords we are in effect narrowing down what the `OOI()` object knows \n",
    "about. In this code the `OOI()` object is called `ooi` so a search looks like `ooi.search(keyword = 'search string', etc)`. \n",
    "After this runs the internal state of `ooi` changes to reflect the search results: It knows about less.\n",
    "\n",
    "\n",
    "Once we have found a very specific search result of interest the `ooi` object can issue a data request \n",
    "using `ooi.request_data(...args...)`.  This data request will use the narrowed-down search perspective \n",
    "so as not to order extraneous data. Ideally each data request is focused on only one instrument. This \n",
    "helps organize data access within the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ooi.search()` second example\n",
    "\n",
    "We narrow the search using keywords `site`, `node` and `instrument`. \n",
    "The `ooi.instruments` result from above provides the vocabulary to use for keyword arguments: \n",
    "\n",
    "- `site` keyword is taken from the `site_name` column\n",
    "  - for example `Oregon Slope Base Seafloor` suggests using `oregon slope base` as the keyword value\n",
    "- `node` keyword is taken from the `infrastructure_name` column\n",
    "  - for example 'Shallow Profiler (SF01A)` suggests keyword `shallow profiler` (notice these are not case-sensitive)\n",
    "- `instrument` keyword is taken from the `instrument_name` column\n",
    "  - for example `3-Wavelength Fluorometer` suggests keyword `fluorometer`\n",
    "  \n",
    "\n",
    "\n",
    "Once the narrow search runs we look at the `ooi.instruments` attribute to see how narrow the results are.\n",
    "This prints as a table where -- as in example one -- the results are sorted into *one instrument per row*.\n",
    "This can confirm whether the objective of narrowing the search down to a single instrument was met.\n",
    "\n",
    "\n",
    "We run the `.data_availability()` method. This gives two outputs: A **table** and below that a \n",
    "**time series graphic**.  The table lists each instrument as a separate column. These columns are \n",
    "then transposed for the time series graphic: One row of boxes for each instrument. \n",
    "\n",
    "\n",
    "***Detail: The green `.data_availability()` chart may fail to render in some cases. Re-running the cell might help.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learn_yodapy: \n",
    "    ooi.search(region='endurance', site='oregon offshore', node='shallow profiler', instrument='fluorometer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learn_yodapy: \n",
    "    ooi.instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learn_yodapy: \n",
    "    ooi.data_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see fluorometers available at Oregon Offshore (without using the 'node' keyword)\n",
    "# \n",
    "#   filters endurance + oregon offshore + fluorometer turn up 7 hits...\n",
    "#     2 are Oregon Offshore Surface Mooring: 3 wavelength... of future interest in expanding the MODIS connection\n",
    "#     2 are Oregon Offshore deep profiler CDOM fluorometer\n",
    "#     2 are Oregon Offshore deep profiler 2 wavelength...    of future interest also (not sure if this is on the RCA)\n",
    "#     1 is Oregon Offshore shallow profiler 3 wavelength     *** Current interest: RCA MODIS connect ***\n",
    "#\n",
    "# ooi.search(region='endurance', site='oregon offshore', instrument='fluorometer')\n",
    "# ooi.instruments\n",
    "# ooi.data_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ooi.search() call: \n",
    "# \n",
    "# ooi.search(region='cabled', instrument='fluorometer') \n",
    "# \n",
    "# produces 12 hits. Here is the breakdown; where results suggest site and node search keywords. \n",
    "#  Note that Deep Profiler sites have degeneracy in 'recovered_inst' versus 'recovered_wfp' (appear twice)\n",
    "# \n",
    "#     - (4) Axial Base Deep Profiler Mooring (CDOM Fluorometer,  2-Wavelength Fluorometer)\n",
    "#     - (4) Oregon Slope Base Deep Profiler Mooring (CDOM Fluorometer, 2-Wavelength Fluorometer)\n",
    "#     - (1) Oregon Slope Base Shallow Profiler Mooring (200m Platform; 2-Wavelength Fluorometer)\n",
    "#     - (1) Oregon Slope Base Shallow Profiler Mooring (Shallow Profiler; 3-Wavelength Fluorometer)\n",
    "#     - (1) Axial Base Shallow Profiler Mooring (200m Platform; 2-Wavelength Fluorometer)\n",
    "#     - (1) Axial Base Shallow Profiler Mooring (Shallow Profiler; 3-Wavelength Fluorometer)\n",
    "\n",
    "# Resulting searches: Choose one of these...\n",
    "if learn_yodapy: \n",
    "    ooi.search(region='cabled', site='oregon slope base', node='shallow', instrument='fluorometer')\n",
    "# ooi.search(region='cabled', site='oregon slope base', node='200m', instrument='fluorometer')\n",
    "# ooi.search(region='cabled', site='axial base', node='shallow', instrument='fluorometer')\n",
    "# ooi.search(region='cabled', site='axial base', node='200m', instrument='fluorometer')\n",
    "\n",
    "# ...and run...\n",
    "if learn_yodapy: \n",
    "    ooi.data_availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transition to data request\n",
    "\n",
    "The following cells include code for requesting data from OOI. From this point onward the \n",
    "narrative will be less detailed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the above cell narrowed the search results to a single instrument. Assume also that we \n",
    "#   are interested in June 1 -- September 15 of 2019. We now use the ooi object to generate a \n",
    "#   data request.\n",
    "#\n",
    "# .request_data() generates a data request\n",
    "# .to_xarray() polls the OOI system until the order completes; this will take a couple of minutes\n",
    "#\n",
    "# begin_date = '2019-06-01'\n",
    "# end_date = '2019-09-15'\n",
    "# ooi.request_data(begin_date=begin_date, end_date=end_date)\n",
    "# ds = ooi.to_xarray()\n",
    "# len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to download the data (possibly multiple files) from a completed data request from above\n",
    "# \n",
    "# filenamelist = ooi.download_netcdfs()\n",
    "# len(filenamelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two intermezzos follow\n",
    "\n",
    "- Managing (hundreds of MB) datasets in this Jupyter environment\n",
    "- Bring in surface chlorophyll data from the MODIS satellite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data management intermezzo\n",
    "\n",
    "\n",
    "### What is the issue here? \n",
    "\n",
    "\n",
    "This narrative is provided as an IPython notebook (really a Jupyter notebook) which resides in \n",
    "a Linux sub-directory of the User home directory `~`. This sub-directory is bundled using\n",
    "the `git` utility as an open source repository ('repo') backed up by \n",
    "[`github`](https://github.com/robfatland/chlorophyll).\n",
    "The github service constrains repository size with the idea of backing up code, not data. \n",
    "\n",
    "\n",
    "So far so good. The data considered here exceeds 1GB and needs to be placed elsewhere in the \n",
    "working environment; in fact within a `data` sub-directory not part of the `chlorophyll`\n",
    "repo. We outline one approach for doing this here using the Linux command line, available\n",
    "through a terminal window provided in the Jupyter environment. \n",
    "\n",
    "\n",
    "\n",
    "#### File resources\n",
    "\n",
    "\n",
    "The code above pulls NetCDF files to a local `chlorophyll` repository directory. \n",
    "In practice this `github` repository directory does not have capacity for \n",
    "large data files (hundreds of MB). To deal with this (at the moment) we relocate \n",
    "the data files outside the repository and access them by creating symbolic \n",
    "links. Here is a sketch of the directory structure:\n",
    "\n",
    "\n",
    "```\n",
    "home directory ~ has sub-directories:\n",
    "\n",
    ".yodapy                    chlorophyll                    data\n",
    "\n",
    "(OOI credentials)          (IPython notebooks)            sub-dir 'chlorophyll'\n",
    "\n",
    "                                                              sub-dir 'OregonSlopeBase'\n",
    "                                                          \n",
    "                                                                  sub-dir 'ShallowProfiler'\n",
    "                                                          \n",
    "                                                                      ...includes 730MB of data\n",
    "```\n",
    "\n",
    "\n",
    "The symbolic link command looks like this, noting the distinction between `chlorophyll`\n",
    "as a sub-directory of `data` versus `chlorophyll` as the repository directory:\n",
    "\n",
    "\n",
    "```\n",
    "ln -s ~/data/chlorophyll/SiteDir/InstrumentDir/filename.nc ~/chlorophyll/Identifier_00XX.nc\n",
    "```\n",
    "\n",
    "\n",
    "The code uses the `xarray` (multi-file) `xr.open_mfdataset(\"Identifier*.nc\")` Dataset generator to \n",
    "open possibly multiple files as a single `Dataset`. \n",
    "\n",
    "\n",
    "These data are (upon arrival) ordered under dimension = observation number `obs`.\n",
    "The data are immediately modified to use dimension = `time`.\n",
    "\n",
    "\n",
    "Here is the current state of data holdings in this environment:\n",
    "\n",
    "\n",
    "```\n",
    "SymLink                                 Site               Instrument  Sensor        Got it\n",
    "-----------                             ---------          ----------  ---------     ---------\n",
    "OreOff_ShallProf_Fluor_000*.nc          Oregon Offshore    shallow     fluor chlor     X        \n",
    "\n",
    "OreSlope_ShallProf_Fluor_000*.nc        Oregon Slope Base  shallow     fluor chlor     X  \n",
    "OreSlope_200m_Fluor_000*.nc             Oregon Slope Base  200m        fluor chlor     X\n",
    "\n",
    "AxialBase_ShallProf_Fluor_000*.nc       Oregon Slope Base  shallow     fluor chlor     X\n",
    "AxialBase_200m_Fluor_000*.nc            Oregon Slope Base  200m        fluor chlor     not yet\n",
    "AxialBase_DeepProf_Fluor_000*.nc        Oregon Slope Base  deep        fluor chlor     not yet\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Skip-to-here point) MODIS intermezzo \n",
    "\n",
    "\n",
    "#### This section builds an `xarray Dataset` by hand from a small set of data points.\n",
    "\n",
    "\n",
    "At this point having ordered data and placed it nearby we are done using `yodapy`.\n",
    "From here on we focus on `xarray`, `matplotlib` and other Python utilities. \n",
    "\n",
    "\n",
    "MODIS estimates of surface chlorophyll at the Oregon Slope Base site are provided\n",
    "by Sarah Barnes and Derya Gumustel. (link to their nbk here) There are a dozen or so valid\n",
    "observations in summer 2019. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code constructs a MODIS observation DataArray from two lists: A date list and a data list.\n",
    "#   Additional code demonstrates working with this DataArray and subsequently an xarray Dataset.\n",
    "\n",
    "# MODIS dates of observation\n",
    "mdate = [dt64('2019-06-02T11:15:00.0'), \\\n",
    "         dt64('2019-06-10T11:55:01.0'), \\\n",
    "         dt64('2019-06-18T11:15:00.0'), \\\n",
    "         dt64('2019-06-26T11:55:01.0'), \\\n",
    "         dt64('2019-07-04T11:15:00.0'), \\\n",
    "         dt64('2019-07-12T11:55:01.0'), \\\n",
    "         dt64('2019-07-20T11:15:00.0'), \\\n",
    "         dt64('2019-07-28T11:55:01.0'), \\\n",
    "         dt64('2019-08-05T11:15:00.0'), \\\n",
    "         dt64('2019-08-13T11:55:01.0'), \\\n",
    "         dt64('2019-08-21T11:15:00.0'), \\\n",
    "         dt64('2019-08-29T11:55:01.0')]\n",
    "\n",
    "# MODIS corresponding surface chlorophyll estimates\n",
    "mchl = [0.3483194, 0.49131608, 0.48018616, np.nan, np.nan, 0.2037715, 0.26320615, 0.3066225, \\\n",
    "        0.35098818, 0.579521, 0.67963886, 0.58974856]\n",
    "\n",
    "# Translating these two lists into a MODIS DataArray\n",
    "mda = xr.DataArray(mchl, dims=('time'), coords={'time': mdate})\n",
    "mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given this DataArray: Provide an example of retrieving the numerical data values.\n",
    "#   Noting that the .values attribute provides an array of floats\n",
    "print(mda.values)\n",
    "print()\n",
    "print(mda.values[0])\n",
    "print()\n",
    "print('The mean of the numerical values is ' + \"%5.3f\" % mda.values[~np.isnan(mda.values)].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deconstructing that last print statement above\n",
    "\n",
    "\n",
    "In the preceding code block the final `print()` is a bit dense so let's deconstruct it.\n",
    "\n",
    "\n",
    "- `\"%5.3f\" % x` is a format statement for printing a float value `x` with three decimal places. \n",
    "- `mda.values` is a `numpy ndarray` (not a list) of the chlorophyll estimates from MODIS. \n",
    "  - A `DataArray` is thematically just one type of data\n",
    "- `np.isnan(...ndarray...)` is also of type `numpy ndarray`, in this case boolean `True` or `False` values\n",
    "  - `True` means the corresponding DataArray element is a `nan`; no valid data present\n",
    "- `~np.isnan(...ndarray...)` applies logical NOT to the prior result so that 'True' means 'valid data'\n",
    "- `mda.values[~np.isnan(...)]` reduces `mda.values` to only valid data: The boolean array is used as a mask\n",
    "- `mda.values[...].mean()` returns the mean of the reduced 'only valid data' result above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda.plot()      # there is no ambiguity about what to plot as a DataArray has just one type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = xr.Dataset({'MODIS chlorophyll': mda})       # The DataArray is translated into a Dataset\n",
    "mds.attrs['units']='µg L-1'                        # Adding units as a metadata attribute\n",
    "mds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODIS surface chlorophyll \n",
    "#### Summer 2019, over the Regional Cabled Array off Oregon coast\n",
    "\n",
    "In sequence: June 18, July 20, August 21, 2019.\n",
    "\n",
    "<BR>\n",
    "<img src=\"./MODIS_chlorophyll_18JUN2019.png\" style=\"float: left;\" alt=\"drawing\" width=\"550\"/>\n",
    "<div style=\"clear: left\"><BR>\n",
    "\n",
    "<BR>\n",
    "<img src=\"./MODIS_chlorophyll_20JUL2019.png\" style=\"float: left;\" alt=\"drawing\" width=\"550\"/>\n",
    "<div style=\"clear: left\"><BR>\n",
    "\n",
    "<BR>\n",
    "<img src=\"./MODIS_chlorophyll_21AUG2019.png\" style=\"float: left;\" alt=\"drawing\" width=\"550\"/>\n",
    "<div style=\"clear: left\"><BR>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section on Cabled Array Oregon Slope Base fluorometer-derived chlorophyll data\n",
    "\n",
    "Multiple local data files can be opened at this point as a single Dataset using `xarray`:\n",
    "\n",
    "```\n",
    "ds=xr.open_mfdataset(...filename description string...)\n",
    "ds = ds.swap_dims({'obs':'time'})\n",
    "```\n",
    "\n",
    "This swaps out observation number in favor of time as the operative dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version uses wildcard notation on pre-existing data files\n",
    "# Endurance array 'Oregon Offshore' site data, 200 meter platform at Oregon Slope Base, Axial Base shallow profiler\n",
    "#   ds = xr.open_mfdataset('/home/jovyan/chlorophyll/OreOff_ShallProf_Fluor_000*.nc')\n",
    "#   ds = xr.open_mfdataset('/home/jovyan/chlorophyll/OreSlope_200m_Fluor_000*.nc')\n",
    "#   ds = xr.open_mfdataset('/home/jovyan/chlorophyll/AxialBase_ShallProf_Fluor_000*.nc')\n",
    "\n",
    "# Cabled Array 'Oregon Slope Base' site data:\n",
    "ds = xr.open_mfdataset('/home/jovyan/chlorophyll/OreSlope_ShallProf_Fluor_000*.nc')\n",
    "ds = ds.swap_dims({'obs':'time'})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to get a check of the units for chlorophyll \n",
    "\n",
    "ds.fluorometric_chlorophyll_a.units\n",
    "\n",
    "# one can make a quick plot of (say) the chlorophyll with time via\n",
    "# p = ds.fluorometric_chlorophyll_a.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section: Oregon Slope Base Shallow Profiler near-surface comparison to MODIS\n",
    "\n",
    "\n",
    "The Oregon Slope Base site has a depth of about 2900 meters and is located at the base of the continental shelf \n",
    "west of Oregon. The fluorometer data are collected over the course of a day as nine profile runs from a depth\n",
    "of 200 meters to near the surface. Between profiles that profiler pod is at rest on a platform that is always\n",
    "at a depth of 200 meters. The sampling rate is a little less than on sample per second. \n",
    "\n",
    "\n",
    "The objective in this section is to create an approximate record of near-surface chlorophyll (all measurements \n",
    "above say 25 meter depth) and compare that with the MODIS values for the same site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `ds.time[0:20], ds.time[-20:-1]`\n",
    "to see example timestamps at the start and end of the Dataset.\n",
    "\n",
    "The following code produces timedelta64 results from datetime64 values. \n",
    "The `.item()` method copies an ndarray element to a scalar and returns that scalar.\n",
    "With no arguments `.item()` is converting a single-element array into a scalar.\n",
    "All three lines of code return 1.128 seconds as the interval between samples.\n",
    "\n",
    "```\n",
    "(ds.time[1].values-ds.time[0].values).item()*1.e-9             # inter-sample interval in seconds\n",
    "(ds.time[-1].values-ds.time[-2].values).item()*1.e-9           # and the same at the end; same result\n",
    "(ds.time[1901000].values-ds.time[1900000].values).item()*1.e-9*1.e-3           # longer interval\n",
    "```\n",
    "\n",
    "Latitude and longitude are fixed.\n",
    "\n",
    "```\n",
    "print(len(ds.lat))\n",
    "ds.lat[3000000:3000007].values       # fixed: the sensor does not move horizontally (much)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dss is Dataset subset: using where() to select for the shallow depth range, \"above so-many meters\"\n",
    "#\n",
    "# < 25 gives 383k points\n",
    "# < 20 gives 278k points\n",
    "# < 15 gives 144k points\n",
    "# < 10 gives 44k points \n",
    "\n",
    "dss=ds.where(ds.int_ctd_pressure < 25., drop=True)    # dss is a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss.dims, ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chlor_a = dss.fluorometric_chlorophyll_a\n",
    "print(type(chlor_a))                         # will be a DataArray\n",
    "pressure = dss.int_ctd_pressure\n",
    "# t0 = dt64('2019-06-15T00:00')\n",
    "t0 = dt64('2019-07-10T00:00')                # slightly precedes the second (contiguous) MODIS data interval\n",
    "t1 = dt64('2019-09-01T00:00')\n",
    "print(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_x_axis = dss.time\n",
    "type(time_x_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the .rolling() method culls out 600 consecutive values at a time; whereupon .mean() is applied\n",
    "dss_chlor_mean = dss.fluorometric_chlorophyll_a.rolling(time=600, center=True).mean()\n",
    "\n",
    "# This also works to produce locally minimal data; but it is not very interesting\n",
    "# dss_chlor_min = dss.fluorometric_chlorophyll_a.rolling(time=600).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,a=plt.subplots(3, 1, figsize=(14,21))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# This works to produce a line plot for shallow profiler chlorophyll (rolling mean): \n",
    "# a[0].plot(time_x_axis, dss_chlor_mean, color='b')\n",
    "a[0].scatter(time_x_axis.values, dss_chlor_mean, color='b', marker= 'o', s = 4.0)\n",
    "a[1].scatter(pressure, chlor_a, color='b', marker= ',', s = 1.0) \n",
    "# a[2].plot(time_x_axis, pressure, color='k') \n",
    "a[2].scatter(time_x_axis.values, pressure, color='k', marker=',', s=1.0) \n",
    "\n",
    "a[0].set(ylim=(0., 1.5), xlim = (t0, t1), title='Chlorophyll over summer 2019: red = MODIS, blue = near-surface shallow profiler')\n",
    "a[1].set(ylim=(0., 1.6), xlim = (4., 21.), title='chlor with pressure')\n",
    "a[2].set(ylim=(21., 4.), xlim = (t0, t1), title='pressure with time')\n",
    "\n",
    "a[0].plot(mda.time, mda, color='r', marker='D', markersize = 9., linestyle='dashed')\n",
    "# a[0].scatter(np.datetime(mda.time), mda, color='r', marker= ',', s = 36.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section: Curtain plots of several profiler sensors\n",
    "\n",
    "Incomplete. Missing are the lower charts and an automated means of determining the mapping range for each type of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes upwards of 10 minutes to run so I False'd it out by default\n",
    "\n",
    "if False: \n",
    "    t0 = dt64('2019-07-10T00:00')                \n",
    "    t1 = dt64('2019-09-01T00:00')\n",
    "\n",
    "    pressure    = ds.int_ctd_pressure\n",
    "    time_x_axis = ds.time\n",
    "    chlor       = ds.fluorometric_chlorophyll_a\n",
    "    cdom        = ds.fluorometric_cdom\n",
    "    volscat     = ds.total_volume_scattering_coefficient\n",
    "    temp        = ds.seawater_temperature\n",
    "    salinity    = ds.practical_salinity\n",
    "    seascat     = ds.seawater_scattering_coefficient\n",
    "    optiback    = ds.optical_backscatter\n",
    "\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    p,a=plt.subplots(7, 1, figsize=(20,49))\n",
    "\n",
    "    aindex = 0\n",
    "    norm = mplcolors.Normalize(vmin=0.0,vmax=0.7)\n",
    "    a[aindex].scatter(time_x_axis.values, pressure, cmap='jet', c=chlor, norm=norm, marker= ',', s = 1.0)\n",
    "    a[aindex].set(ylim=(200., 0.0), xlim = (t0, t1))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    a[aindex].set(title='Chlorophyll with time and depth')\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    a[aindex].set_ylabel('Pressure (dbar)')\n",
    "    a[aindex].set_xlabel('Date')\n",
    "\n",
    "    aindex = 1\n",
    "    norm = mplcolors.Normalize(vmin=7.0,vmax=14.)\n",
    "    a[aindex].scatter(time_x_axis.values, pressure, cmap='jet', c=temp, norm=norm, marker= ',', s = 1.0)\n",
    "    a[aindex].set(ylim=(200., 0.0), xlim = (t0, t1))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    a[aindex].set(title='Temperature with time and depth')\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    a[aindex].set_ylabel('Pressure (dbar)')\n",
    "    a[aindex].set_xlabel('Date')\n",
    "\n",
    "    aindex = 2\n",
    "    norm = mplcolors.Normalize(vmin=7.0,vmax=14.)\n",
    "    a[aindex].scatter(time_x_axis.values, pressure, cmap='jet', c=optiback, norm=norm, marker= ',', s = 1.0)\n",
    "    a[aindex].set(ylim=(200., 0.0), xlim = (t0, t1))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    a[aindex].set(title='Optical backscatter with time and depth')\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    a[aindex].set_ylabel('Pressure (dbar)')\n",
    "    a[aindex].set_xlabel('Date')\n",
    "\n",
    "    aindex = 3\n",
    "    norm = mplcolors.Normalize(vmin=7.0,vmax=14.)\n",
    "    a[aindex].scatter(time_x_axis.values, pressure, cmap='jet', c=salinity, norm=norm, marker= ',', s = 1.0)\n",
    "    a[aindex].set(ylim=(200., 0.0), xlim = (t0, t1))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    a[aindex].set(title='Salinity with time and depth')\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    a[aindex].set_ylabel('Pressure (dbar)')\n",
    "    a[aindex].set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section: Expanded chlorophyll curtain plots\n",
    "\n",
    "Treats the below-100-meters and above-100-meters as two separate colormap tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mplcolors\n",
    "\n",
    "t0 = dt64('2019-06-01T00:00')                \n",
    "t1 = dt64('2019-09-01T00:00')\n",
    "\n",
    "pressure = ds.int_ctd_pressure\n",
    "time_x_axis = ds.time\n",
    "chlor = ds.fluorometric_chlorophyll_a\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "p,a=plt.subplots(2, 1, figsize=(14,14))\n",
    "\n",
    "norm = mplcolors.Normalize(vmin=0.0,vmax=0.5)\n",
    "a[0].scatter(time_x_axis.values, pressure, cmap='jet', c=chlor, norm=norm, marker= ',', s = 1.0)\n",
    "a[0].set(ylim=(100., 0.0), xlim = (t0, t1))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "a[0].set(title='Chlorophyll with time and depth')\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "a[0].set_ylabel('Pressure (dbar)')\n",
    "a[0].set_xlabel('Date')\n",
    "\n",
    "norm = mplcolors.Normalize(vmin=0.0,vmax=0.1)\n",
    "a[1].scatter(time_x_axis.values, pressure, cmap='jet', c=chlor, norm=norm, marker= ',', s = 1.0)\n",
    "a[1].set(ylim=(200., 100.0), xlim = (t0, t1))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "a[1].set(title='Chlorophyll with time and depth')\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "a[1].set_ylabel('Pressure (dbar)')\n",
    "a[1].set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section: Double chlorophyll lens July 20 2019 (3 profiles) \n",
    "\n",
    "\n",
    "We can ask whether the recorded signal is a mirror image as the profiler rises and falls. To see this\n",
    "it helps to have a double-y-axis as shown in [this example](https://matplotlib.org/gallery/api/two_scales.html). \n",
    "\n",
    "\n",
    "Below we have three consecutive profiles over the course of seven hours which all demonstrate a double-maximum\n",
    "in chlorophyll concentration: One at about 30 meters and another at about 55 meters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Precision section works with precise times versus day-scale\n",
    "#   The precise times are an experiment in using 2 hours 40 minutes to chop up the 9 profiles in the day in a regular manner...\n",
    "#   but a better approach would be to detect the profiles and time-box each one individually. \n",
    "# \n",
    "\n",
    "t0 = dt64('2019-07-20T11:00')\n",
    "t1 = dt64('2019-07-20T18:00')\n",
    "dss = ds.sel(time=slice(t0, t1))\n",
    "len(dss.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,a=plt.subplots(2, 1, figsize=(14,14))\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "chlor_a = dss.fluorometric_chlorophyll_a\n",
    "chlor_a_min = chlor_a.rolling(time=60, center=True).min()\n",
    "pressure = dss.int_ctd_pressure\n",
    "\n",
    "a[0].plot(dss.time, chlor_a_min, color='g')\n",
    "a[1].scatter(pressure, chlor_a, color='k', marker= 'D', s = 4.0) \n",
    "\n",
    "a[0].set(ylim=(0., 0.55), xlim = (t0, t1), title='Shallow profiler: Chlorophyll (green) and pressure (blue) over seven hours')\n",
    "a[1].set(ylim=(0., 0.8), xlim = (0., 200.), title='Persistent double maximum: Chlorophyll with pressure')\n",
    "\n",
    "a[0].set_ylabel('Chlorophyll (ug L-1)')\n",
    "a[0].set_xlabel('Time: July 20 2019, hours 11 - 18')\n",
    "a[0].tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "a[1].set_ylabel('Chlorophyll (ug L-1)')\n",
    "a[1].set_xlabel('Pressure (dbar)')\n",
    "a[1].tick_params(axis='y', labelcolor='k')\n",
    "\n",
    "a0p = a[0].twinx()\n",
    "a0p.set_ylabel('Pressure (dbar)')\n",
    "a0p.plot(dss.time, pressure, color='blue')\n",
    "a0p.tick_params(axis='y', labelcolor='blue')\n",
    "a0p.set(ylim=(200., 0.), title='   ')\n",
    "\n",
    "# Optional formatting code: p.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section: Animating chlorophyll depth profiles\n",
    "\n",
    "Each chart will be one profile in the time sequence 9-profiles-per-day from August 1 to August 15.\n",
    "\n",
    "* [JS Animation in Jupyter notebooks 2nd blog post (update to original)](http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-as-interactive-javascript-widgets/)\n",
    "* `HTML(anim.to_html5_video())` generates the animation with no controls\n",
    "* `HTML(anim.to_jshtml())` generates the animation inside a playback control widget\n",
    "\n",
    "*ffmpeg* installation is necessary: `conda install -c conda-forge ffmpeg`\n",
    "\n",
    "##### In both cases I get a static view below the animated one; so one bug to work out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This, it turns out, is necessary for the HTML() call below\n",
    "# from ipywidgets import *\n",
    "# from traitlets import dlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['animation.ffmpeg_path'] = '/srv/conda/envs/notebook/bin/ffmpeg'      # Make sure matplotlib can find the movie writer 'ffmpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that !which ffmpeg returns /srv/conda/envs/notebook/bin/ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set up the parameters of the chart to be animated\n",
    "# Second define initialization and animation functions\n",
    "# Third define an animation object\n",
    "# Fourth run the animation's html5 generator method .to_html5_video()\n",
    "#   There is also a playback-control-widget javascript version: .to_jshtml())\n",
    "\n",
    "# First: Chart setup\n",
    "fig, ax = plt.subplots(figsize=(7,14))     # creates a vertically elongated chart (7 is width)\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "ax.set_xlim(( 0., 1.))\n",
    "ax.set_ylim((125., 0.))\n",
    "ax.tick_params(axis='y', labelcolor='k')\n",
    "ax.set_ylabel('Pressure (dbar)', fontsize=16)\n",
    "ax.set_xlabel('Chlorophyll (ug L-1)', fontsize=16)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "ax.set(title='Time series: \\n Chlorophyll (x) with Pressure (y)')\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "# divides the day up into approximately 9 intervals of 2 hours 40 minutes\n",
    "proftime = ['00:00', '02:40', '05:20', '08:00', '10:40', '13:20', '16:00', '18:40', '21:20', '23:59']\n",
    "\n",
    "# Each render of the profile chart will try to blank out the prior datetime\n",
    "prev_msg = '              '\n",
    "\n",
    "# matplotlib plot object assigned to variable 'line' with some interesting syntax 'line,'\n",
    "#   ax.plot() returns a tuple with just one element\n",
    "#   using 'line,' syntax assigns the first (and only) element of this tuple to 'line'\n",
    "#   There are other syntactical alternatives to this economical convention\n",
    "#     Equivalent: [line] = ax.plot([], [], lw=3)\n",
    "#     Equivalent: line = ax.plot([], [], lw=3)[0]\n",
    "line, = ax.plot([], [], lw=3)\n",
    "\n",
    "# A scatter plot is a more involved proposition. \n",
    "# The following does not work:\n",
    "#   line, = ax.scatter([], [], color='k', marker='D', s = 4.0)\n",
    "\n",
    "# Second: Define the initialization and animation functions used to animate\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "def animate(i):\n",
    "    global prev_msg\n",
    "    day = i//9 + 1\n",
    "    prof = i%9\n",
    "    if day < 10: day1 = '0' + str(day)\n",
    "    else: day1 = str(day)\n",
    "    day2 = day1\n",
    "    \n",
    "    # '2019-07-20T11:00'\n",
    "    t0string = '2019-08-' + day1 + 'T' + proftime[prof]\n",
    "    t1string = '2019-08-' + day2 + 'T' + proftime[prof+1]    \n",
    "    t0 = dt64(t0string)\n",
    "    t1 = dt64(t1string)\n",
    "    ds_1day = ds.sel(time=slice(t0, t1))\n",
    "\n",
    "    chlor_a = ds_1day.fluorometric_chlorophyll_a\n",
    "    chlor_a_min = chlor_a.rolling(time=60, center=True).min()\n",
    "    pressure = ds_1day.int_ctd_pressure\n",
    "    \n",
    "    # ax.scatter(pressure, chlor_a, color='k', marker= 'D', s = 4.0) \n",
    "\n",
    "    line.set_data(chlor_a_min, pressure)\n",
    "\n",
    "    # speculative line of code...\n",
    "    ax.text(0.5, 120., prev_msg, rotation=0, fontsize=18, color='white', fontweight='bold')\n",
    "    ax.text(0.5, 120., str(t0), rotation=0, fontsize=18, color='blue', fontweight='bold')\n",
    "    prev_msg = str(t0)\n",
    "\n",
    "    return (line,)\n",
    "\n",
    "# Third: define the animation object\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=15*9, interval=100, blit=True)\n",
    "\n",
    "# Fourth: Generate the animated video result\n",
    "# simple animation, no controls\n",
    "HTML(anim.to_html5_video())                      \n",
    "# \n",
    "# second version: with controls: \n",
    "# HTML(anim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - - - - - - - - - - - -\n",
    "# Source Material Only\n",
    "\n",
    "From work with Don November 13, 2019 on getting yodapy working properly; including skipping over to the original data source to pull NetCDF files...\n",
    "\n",
    "### Filter the following cell for any useful ideas before deleting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ooi.search(region='cabled', site='axial base shallow profiler', node='shallow profiler', instrument='CTD')\n",
    "# ooi.instruments                    # an attribute\n",
    "# ooi.data_availability()\n",
    "\n",
    "# This cell does not run by default because it generates a data retrieve\n",
    "if False:\n",
    "    begin_date = '2018-01-01'\n",
    "    end_date = '2018-01-02'\n",
    "    ooi.request_data(begin_date=begin_date, end_date=end_date)\n",
    "\n",
    "# Once the data order is complete we need a way of placing the URL in the ooi object so we do not have\n",
    "#   to repeat the query. That goes into the yodapy README also. Are you tired of re-running this cell? \n",
    "#   Just run ooi.to_xarray() and it will do the polling for you. \n",
    "#\n",
    "# This is also 'Falsed out'\n",
    "if False: \n",
    "    ooi.check_status()\n",
    "\n",
    "# In the above cell ooi.check_status() can be re-run as a status check until the request is filled.\n",
    "# If instead we use the .to_xarray() method the polling loop on the data request is automated. This \n",
    "#   could take some time; but when it works the end result is a list of Xarray Datasets. Why is this \n",
    "#   a list? Because the requested time range may produce results that are segmented in time, i.e. \n",
    "#   several Datasets. By returning them in sequence as a list we hope to recover everything available\n",
    "#   in a time-contiguous fashion (subject to data dropouts if there are any).\n",
    "if False: \n",
    "    ds = ooi.to_xarray()\n",
    "    ds[0]\n",
    "\n",
    "# Saving (say the first in the list) Dataset to a NetCDF file via .to_netcdf() will not work because \n",
    "# OOI data are not CF-compliant in format\n",
    "# ds[0].to_netcdf('fubar.nc')\n",
    "\n",
    "# This will reach into the OOI system (not the CAVA system) and download and save NetCDF content\n",
    "if False:\n",
    "    filenamelist = ooi.download_netcdfs()\n",
    "    print(len(filenamelist))\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "if False: \n",
    "    ooids = xr.open_dataset(filenamelist[0])  \n",
    "    ooids\n",
    "\n",
    "# better: use open_mfdataset(filenamelist) to concatenate a segmented result\n",
    "# caveat: don't use against hetero instrument results as these will not stack properly in a Dataset\n",
    "\n",
    "# Start over: search specific to chlorophyll via fluorometers. Notice the instruments value is a search term\n",
    "# ooi.search(region='cabled', instrument='fluorometer')\n",
    "# ooi.instruments                    # an attribute\n",
    "# ooi.data_availability()\n",
    "\n",
    "# to reset the filters use ooi.clear() to avoid sub-filtering filtered results to arrive at nothing!\n",
    "\n",
    "# The following table lists possible instruments as *column headers*. This is subsequently \n",
    "#   transposed in the data availability graph: rows for each instrument's time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alert\n",
    "\n",
    "In the foregoing we got 12 fluorometer hits. These do not include \"Oregon Offshore\" which is the distal node\n",
    "of the Endeavor array that sits on the RCA for power and data. This means that it is necessary to go back and\n",
    "re-do the query to pick up Oregon Offshore.\n",
    "\n",
    "\n",
    "## Zarr\n",
    "\n",
    "The following section also touches on zarr files; please expand documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's be specific to the Oregon Slope Base profiler\n",
    "ooi.search(region='cabled', site = 'Oregon Slope Base', node = 'Shallow Profiler', instrument='fluorometer', )\n",
    "ooi.instruments                    # an attribute\n",
    "ooi.data_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    begin_date = '2019-06-01'\n",
    "    end_date = '2019-09-30'\n",
    "    ooi.request_data(begin_date=begin_date, end_date=end_date, time_check = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    chlords = ooi.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    filenamelist = ooi.download_netcdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chlor = xr.open_mfdataset(filenamelist)\n",
    "chlor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many results came back? Remember OOI might chop up the data into contiguous time segments arbitrarily\n",
    "len(filenamelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chlor = chlor.swap_dims({'obs':'time'})\n",
    "chlor.fluorometric_chlorophyll_a.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking ahead; we need zarr...\n",
    "# !pip install zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this cell fails because you need zarr and it is not installed: See previous cell\n",
    "# Looking ahead to zarr\n",
    "import s3fs\n",
    "\n",
    "cavapath = 'io2data-test/data/RS01SBPS-SF01A-3A-FLORTD101-streamed-flort_d_data_record'\n",
    "FS = s3fs.S3FileSystem(anon=True)        # because not using an AWS cred\n",
    "s3ds = xr.open_zarr(store=s3fs.S3Map(cavapath, s3=FS), consolidated=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarrchlor=s3ds.sel(time=slice('2019-06-01', '2019-09-30'))\n",
    "zarrchlor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarrchlor.fluorometric_chlorophyll_a.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    zarrchlor.plot.scatter(x='time', y='int_ctd_pressure', hue='fluorometric_chlorophyll_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ooi.sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ooi.search(region='Coastal Endurance')\n",
    "ooi.instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ooi.search(region='endurance', instrument='fluorometer')\n",
    "ooi.instruments                    # an attribute\n",
    "ooi.data_availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relocate this comment \n",
    "\n",
    "\n",
    "At a low level parquet breaks data in column-wise storage, many small files. Notice this is column-format, not \n",
    "row format as we are accustomed to in CSV files. When you read this into dask... a pandas data frame reads the \n",
    "entire file... but dask works on lazy eval so dask access to a parquet data ensemble (many of these small chunked \n",
    "files) is very efficient as lazy eval. \n",
    "\n",
    "\n",
    "Dask reads this data into a dask data frame (which we can consider virtualized / lazy); and a dask data frame is \n",
    "analogous to a pandas data frame with that virtualization. \n",
    "\n",
    "\n",
    "Athena gives an analogous end-result; it is an AWS service running Apache Hive under the hood. \n",
    "You are charged for every query, beware. The access protocol is a SQL query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource code block\n",
    "\n",
    "\n",
    "This is a 3 x 3 matrix of CTD and related-sensor time series charts from a `data_gallery` IPython notebook. \n",
    "\n",
    "\n",
    "```\n",
    "rn = range(9); rsi = range(7)\n",
    "\n",
    "p,a=plt.subplots(3, 3, figsize=(14,14))\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "a[0,0].plot(ctdF.time, ctdF.depth, color='r');                                  a[0,0].set(ylim=(200.,0.), title='Depth')\n",
    "a[0,1].plot(ctdF.time, ctdF.salinity, color='k');                               a[0,1].set(title='Salinity')\n",
    "a[0,2].plot(ctdF.time, ctdF.temperature, color='b');                            a[0,2].set(title='Temperature')\n",
    "a[1,0].plot(ctdF.time, ctdF.dissolved_oxygen, color='b');                       a[1,0].set(title='Dissolved Oxygen')\n",
    "a[1,1].scatter(phF.time.values, phF.ph_seawater.values, color='r');             a[1,1].set(title='pH')\n",
    "a[1,2].scatter(nitrateF.time.values, nitrateF.scn.values, color='k');           a[1,2].set(title='Nitrate')\n",
    "a[2,0].plot(parF.time, parF.par_counts_output, color='k');                      a[2,0].set(title='Photosynthetic Light')\n",
    "a[2,1].plot(fluorF.time, fluorF.fluorometric_chlorophyll_a, color='b');         a[2,1].set(title='Chlorophyll')\n",
    "a[2,2].plot(siF.time, siF.si0, color='r');                                      a[2,2].set(title='Spectral Irradiance')\n",
    "\n",
    "a[2,0].text(dt64('2017-08-21T07:30'), 155., 'local midnight', rotation=90, fontsize=15, color='blue', fontweight='bold')\n",
    "a[2,2].text(dt64('2017-08-21T07:30'), 4.25, 'local midnight', rotation=90, fontsize=15, color='blue', fontweight='bold')\n",
    "\n",
    "tFmt   = mdates.DateFormatter(\"%H\")                 # an extended format for strftime() is \"%d/%m/%y %H:%M\"\n",
    "t0, t1 = ctdF.time[0].values, ctdF.time[-1].values  # establish same time range for each chart\n",
    "tticks = [dt64('2017-08-21T06:00'), dt64('2017-08-21T12:00'), dt64('2017-08-21T18:00')]\n",
    "\n",
    "for i in rn: j, k = i//3, i%3; a[j, k].set(xlim=(t0, t1),xticks=tticks); a[j, k].xaxis.set_major_formatter(tFmt)\n",
    "print('')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write this up: Two ways of stipulating time slices for a Dataset .sel()\n",
    "\n",
    "do_precision = False\n",
    "\n",
    "if do_precision:\n",
    "    \n",
    "    t0 = dt64('2019-06-01T00:00')\n",
    "    t1 = dt64('2019-06-01T05:20')\n",
    "    dss = ds.sel(time=slice(t0, t1))\n",
    "    \n",
    "else:\n",
    "    t0 = dt64('2019-06-24T00:00')\n",
    "    t1 = dt64('2019-06-28T00:00')\n",
    "    day1 = '24'\n",
    "    day2 = '27'              # will be 'day 27 inclusive' I think\n",
    "    dss = ds.sel(time=slice('2019-06-' + day1, '2019-08-' + day2))\n",
    "\n",
    "len(dss.time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
